# Regression analysis

```{r setup9}
#| echo: false
#| message: false
#| warning: false

library(dplyr)
library(Hmisc)
library(ggplot2)
library(haven)
library(sjPlot)
datadir<-"~/Data/bsa/"
bsa<-read_spss(paste0(datadir,"8849spss_V1/bsa2017_open_enviropol.sav"))
bsa$RAgeCat.f<-droplevels(as_factor(bsa$RAgeCat))
bsa$Rsex.f<-droplevels(as_factor(bsa$Rsex))
bsa$HEdQual3.f<-droplevels(as_factor(bsa$HEdQual3))
```

Regression is one of the most common modelling tools used in social science. The `glm()` function from Base R can be used for fitting linear and non-linear models. These include OLS regression, logistic/probit regression, and more generally any model falling under the Generalized Linear Model (GLM) framework.\
In this section, we will use it to investigate the association between the level of education and whether someone voted or not at the last general elections. But let’s first briefly explore the variables using the `class()` and `table()`:

```{r 9.1}
class(bsa$HEdQual3.f)

table(bsa$HEdQual3.f)
```

and

```{r 9.2}
class(bsa$Voted)

table(bsa$Voted)
```

We converted earlier `HEdQual3` into a factor variable, but as we can see above, `Voted` is still a labelled numeric variable. It is a good idea to convert it to a factor as well. This is not absolutely necessary, but gives greater flexibility, for instance if we need to change the reference category on the go in the regression model.

```{r 9.3}
bsa$Voted.f<-droplevels(as_factor(bsa$Voted)) # As before, factor conversion
levels(bsa$Voted.f)                           # Note that Yes comes before No

```

For greater readability we can also shorten the levels of `HEdQual3.f` using the `level()` function:

```{r 9.3.1}
levels(bsa$HEdQual3.f) ### The original level names  are a bit verbose...

### ... We can shorten them easily
levels(bsa$HEdQual3.f) <- c("Degree","A level and above","GCSE or equiv","No Qual")

table(bsa$HEdQual3.f)
```

What about the levels for our dependent variable? By default, the first level of a factor will be used as the reference category. This can be also checked with the `contrasts()` function. In this case, 1 is associated with ‘No’, so the model will be predicting the probability of NOT voting. If the 1 was associated with ‘Yes’ then the model will be predicting the probability of voting.

```{r 9.3.2}
contrasts(bsa$Voted.f)
```

As we are interested in the latter, we need to change the reference category using the `relevel()` function. We will create a new variable named `Voted2` so as to keep the original variable intact.

```{r 9.5}
# Reverse the order
bsa$Voted2 <- relevel(bsa$Voted.f, ref = "No")

# Check the contrasts
contrasts(bsa$Voted2)
```

Since the outcome variable (`Voted2`) has a binomial distribution, we need to specify to the `glm()` function that we will be fitting a logistic regression model. We will do this by setting the argument `family` to 'binomial' and the `link` function to 'logit'. We could also have used 'probit' instead as a link function. The code below runs the model and stores the result into an object called `fit1`:

```{r 9.6}
fit1 <- glm(Voted2 ~ HEdQual3.f, 
            data=bsa, 
            family=binomial(link=logit)
            )

summary(fit1)
```

To run a model controlling for gender `Rsex`and age `RAgeCat`, one simply needs to add them on the right-hand side of the formula, separated with a plus (+) sign.

```{r 9.7}
fit2 <- glm(Voted2 ~ HEdQual3.f + Rsex.f + RAgeCat.f, 
            data=bsa, 
            family=binomial(link=logit)
            )

summary(fit2)
```

#### Model interpretation {.unnumbered}

`summary()` provides a broad overview of the model output, comparable to other statistical software. But `fit1` and `fit2` contain more information than what is displayed by `summary()`. For an overview, one can type:

```{r 9.8}
ls(fit1)
```

... Which displays a list of all the content items stored by it. We can request specific elements, the regression coefficients, by specifying its name following the `$` sign:

```{r 9.9}
fit1$coefficients # extracting regression coefficients
```

Shortcuts to some of these contents are available as functions such as `coef()` to extract the regression coefficients, or `deviance()` for the log-likelihood of the fitted model.

```{r 9.10}
ls(fit2)
round(fit2$coefficients,2)

### The coef() function will give the same output:
round(coef(fit2),2)
```

It is beyond the remit of this guide to describe the full output of `glm()`. See the [`stats` package documentation](https://stat.ethz.ch/R-manual/R-patched/library/stats/html/glm.html) for more detailed explanations.

#### Computing odds ratios {.unnumbered}

Standard logistic regression coefficients measure the logarithmic effect of variables on the probability of the outcome such as $log(\beta_X)=P(y)$. It is common practice to convert these into odd ratios by exponentiating them, such as that $\beta_X=exp(P(y))$.

Using the `coef()` and `confint()` functions, the code above  respectively extracts the coefficients and the associated 95% confidence intervals from `fit2` then collate them using `cbind()`.

```{r 9.11}
cbind(
  Beta_x=exp(
    coef(fit2)
    ),
  exp(
    confint(fit2)
    )
) 
```

#### Plotting regression coefficients {.unnumbered}

We can visualise the odd ratios and their confidence intervals using the `plot.model()` function from the `sjPlot` package. If not already present, `sjPlot` needs to be installed and loaded first.

```         
install.packages('sjPlot')
```

```{r 9.12}
#| fig.alt: "Horizontal line plot for the odds ratios of the regression of voting behaviour by qualification, age categories and gender together with their confidence intervals"
library(sjPlot)
set_theme(base = theme_minimal()) ### Default sets of options 
plot_model(fit2,
           colors = c("#702082", "#008755") ### Added for better accessibility 
) 
```

#### Assessing model fit {.unnumbered}

The Akaike Information Criterion (AIC) is a measure of relative fit for maximum likelihood fitted models. It is used to compare the improvement in how several models fit some data relative to each other, allowing for the different number of parameters or degrees of freedom. The smaller the AIC, the better the fit. In order for the comparison to be valid, we need to ensure that the models were run with the same number of observations each time. As it is likely that the second model was run on a smaller sample, due to missing values for the Age and Sex variables, we will need to re-run the first one without these.

```{r 9.13}
fit1 <- glm(Voted2 ~ HEdQual3.f, 
            data=bsa%>%filter(!is.na(Rsex.f) & !is.na(RAgeCat.f)), 
            family=binomial(link=logit))

c(fit1$aic,fit2$aic)
```

We can see that the model controlling for gender and sex is a better fit to the data than the one without controls as it has an AIC of 2944.5 against 3244.5 for fit1.

With the information about the deviance from `fit1` and `fit2`, we can also compute the overall significance of the model, that is whether the difference between the deviance (another likelihood-based measure of fit) for the fitted model is significantly different from that of the empty or null model. This is usually carried out by conducting a chi square test, accounting for the differences in the number of parameters (ie degrees of freedom) between the two models. As with other R code, this can be achieved step by step or in one go:

```{r 9.14}
dev.d<-fit2$null.deviance - fit2$deviance # Difference in deviance
df.d<-fit2$df.null - fit2$df.residual     # ... and degrees of freedom
p<-1 - pchisq(dev.d, df.d)
c(dev.d,df.d,p)
```

The Chi square test indicates that the difference in deviance of 370.5 with 10 degrees of freedom is highly significant (P\<.001) \newpage
