{
  "hash": "8bcd9d0552d5c1372c3fe7f9de747438",
  "result": {
    "markdown": "# Introduction\nThis guide provides an introduction to analysing large scale social survey\ndataset using R with examples from the British Social Attitudes Survey 2020. It\nis aimed at two categories of users: \n  \n  1. Those outside higher education, or who do not have access to one commonly used commercial statistical  software such as Stata, SPSS or SAS but who would like to conduct their own analysis beyond what is usually published by data producers such as the Office for National Statistics (for example statistics for specific groups of the population). This guide provides this group of users with a range of procedures that will help them produce straightforward and robust Nanalyses tailored to their needs without spending unnecessary time on learning the inner workings of R. \n\n2. More advanced users who are already familiar with other data analysis tools but who would like to learn how to carry out their analyses in R. \nThe guide therefore focuses on providing succinct  examples of common operations that most users carry out in the course of their research, including how to: \n  \n  - read in and open datasets. \n\n  - do common data manipulation operations. \n\n  - produce simple descriptive statistics or tabulations. \n\n  - use survey weights. \n\nBy contrast with other statistical software,  the R interface is rather minimal\nand consist merely of a terminal.  In line with programming languages such a\nPython or C, R users tend to access it via an interface, or Integrated\nDevelopment Environment (IDE).  This guide uses the R Studio development\nenvironment, one of the most common IDE for R. The data used in this guide is\nthe [British Social Attitudes Survey, 2017, Environment and Politics: Open\n     Access Teaching\n     Dataset](https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=8849),\nwhich can be downloaded from the UK Data Service website without registration.\nThe website also has instructions on how to acquire and download large-scale\nsurvey datasets. Links and further information about the other training\nresources available online are provided at the end of this document. \n\n## What is R ?\n\nR is a free, user developed, object-oriented statistical programming language\nthat  originates in the ‘S’ and ‘S Plus’ languages developed during the 1970s\nand 1980s. It has a large audience in the science and statistics communities and\nis increasingly used in the social sciences for teaching and research purposes. \n\nAnyone can install and use R without charge, and to some extent contribute to\nand amend the existing program itself. R can be downloaded from the\n[Comprehensive R Archive Network (CRAN)](https://cran.r-project.org/) website.\nInstallation instructions as well as guides, tutorials and FAQ are available on\nthe CRAN website.\n\nR is particularly favoured by users who want to develop their own statistical\nfunctions or implement technical advances that are not yet available in\ncommercial packages. The existence of a vast number of user written packages\n(17,672 at the time of writing this guide)  is one of the great strengths of R.\nUsers who want to contribute should be aware that in order to be part of the R\narchive, a minimum set of rules need nonetheless to be followed.\n\nAlthough R can perform most of the analyses available in generalist  software\nsuch as Stata, SPSS, or SAS, it has a broader potential since it can also be\nused for mapping, data mining or machine learning. Being a language also means\nthat there are often several ways to carry out analyses in R, each one with its\nadvantages and inconvenient. Users can also easily produce  publication quality\noutput from R thanks to its integration with the Markdown LaTeX document\npresentation system, and R graphs can also be imported into MS Word or\nLibreOffice documents.\n\n<!-- ## Pros and cons of R relative to other statistical software -->\n  Although R has advantages over other statistical analysis software, it also has\na few downsides, both of which are summarised below.  Users should be reminded\nthat as open-source software, R and its packages are developed by volunteers,\nwhich makes it a very flexible and dynamic project, but at the same time reliant\non developers’ free time and goodwill.\n\n\n\n\n::: {.cell hash='main_body_cache/pdf/table_a7ee434bd65a966be46674fcc1b11298'}\n::: {.cell-output-display}\nTable: Advantages and inconvenients of R\n\n|Pros                                                                                                                                                         |Cons                                                                                                                                                                                                                   |\n|:------------------------------------------------------------------------------------------------------------------------------------------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n|R is free and allows users to perform  almost any analysis they want.                                                                                        |The learning curve may be steep for users who  do not have a prior background in statistics or  programming.                                                                                                           |\n|R puts statistical analysis closer to the reach of  individual citizens rather than specialists.                                                             |                                                                                                                                                                                                                       |\n|                                                                                                                                                             |                                                                                                                                                                                                                       |\n|Transparency of use and programming of the software  and its routines, which improves the peer-reviewing  and quality control of the software in many cases. |                                                                                                                                                                                                                       |\n|Very flexible.                                                                                                                                               |Problem solving (for both advanced users  and beginners)  may be time-consuming, depending  on how common the problem encountered,  and may lead to more time spent solving  technical rather than substantive issues. |\n|                                                                                                                                                             |                                                                                                                                                                                                                       |\n|Availability of a wide range of advanced techniques not provided in other statistical software                                                               |Many people who design R packages are,   or will become busy academics. Packages  can stop being maintained without notice.                                                                                            |\n|                                                                                                                                                             |                                                                                                                                                                                                                       |\n|A very large user base provides abundant  documentation, tutorials, and web pages.                                                                           |                                                                                                                                                                                                                       |\n:::\n:::\n\n\n\n\nThere are several (sometimes many) ways of achieving a particular result in R.\nThis can be confusing for novice researchers, but at the same time will allow  users to\ntightly adjust their programmes to their needs.\n\\newpage\n\n\n# Using R: essential information\n## Download and installation \n\n\n\n\n\n\n\n\nR can be downloaded for free from the [CRAN website](https://cran.r-project.org/) and run like any other Windows\napplication. Versions for Mac and Linux are also available.  After installation,\nthe standard and rather minimalist R interface that appears when the programme\nis launched is shown below.\n\n\n<!-- ```{r 2.1, echo=FALSE,fig.cap=\"The standard R interface\",fig.pos=\"H\",out.width = \"500pt\", }  -->\n<!-- library(foreign) -->\n<!-- knitr::include_graphics(\"pics/screen2.1.jpg\") -->\n<!-- ```  -->\n![The standard R interface](pics/screen2.1.jpg){fig.alt=\"Screenshot of the standard R Windows interface\"}\n\nThis interface merely allows the user to type in commands one by one in the\nconsole, and to install packages via pull-down menus.  However, this basic\ninstallation, although fully functional, is rather minimal, not very ergonomic\nor user friendly.   As with other statistical software, the primary way of\ninteracting with R for most  is to write programs, even basic ones in a syntax\nfile (also called script file) that is saved and run whenever needed, which is\nnot directly feasible with the standard R GUI.\n\nIt is therefore highly recommended to  use  R via an Integrated Development\nEnvironment (ie a more sophisticated user interface) such as\n[RStudio](https://www.rstudio.com/products/rstudio/download/) for beginners to\nintermediate users or the [StatEt module](https://www.eclipse.org/statet/news/)\nfor  [Eclipse](https://www.eclipse.org/downloads/)  for more advanced\nprogrammers. Both are free, available for Windows, MacOS and Linux and offer\nusers  a large number of  additional functionalities, such as syntax\nhighlighting, integration with Github. Given that it probably has the largest\nnumber of users RStudio will be used to demonstrate examplkes of R syntax in\nthe remainder of this document. In order for this guide to remain as universal\nas possible, we will not rely on the advanced features of RStudio, instead using\nit merely as an interface to the R engine. \n\n## Installing and setting up RStudio\n\nRStudio needs to be installed separately from R. The program can be downloaded\nfrom  [the RStudio website](https://www.rstudio.com/products/rstudio/download/).\nThe site will automatically generate  a link to the version most compatible with\nthe computer used to access it. Once downloaded double click on the file  and\nfollow the installation instructions. \n\nBy default, the R Studio interface consists of  four main panels, respectively\nknown as the script editor (top left panel), the console (bottom left panel),\nthe Environment (top right panel) and the File/Directory/Help (bottom right panel).\n\n![The R Studio default interface](pics/screen2.2.png){fig.alt=\"Screenshot of the standard RStudio interface with four panes: top left: script; bottom left: console; top right: global environment; bottom right: files or help\"}\n\nAs such a complex interface can be visually overwhelming for some users and is\nnot required for the purpose of  this guide, we will minimise the Global\nEnvironment and Files/Directory/Help panels by clicking in the center of the\nwindow and dragging right to the edge of the screen. This way, only the script\nand console  panels remain visible.   The tiling of the panels can be customised\nin `Tools>Global Options>Pane Layout`. For instance, Script can be moved to the\nbottom of the window and Console to the top: \n\n![A customised R Studio interface](pics/screen2.3.png){fig.alt=\"Screenshot of the customised R Studio interface, with the console pane at the top and the script pane at the bottom\"}\n\n## Interacting with R\n\nAs already mentioned, one can type R commands directly in the console of RStudio\nand/or by typing sequences of commands in a script file. \n\nMost R commands adopt the following syntax: \n  \n``` \n> command(parameter1, parameter2, ...) \n```\n`All` R commands are followed by brackets, even if there are no parameters. \n\nIn the following example we are going to set up the default working directory, that is  the default location for opening and storing files, by using the `getwd()` and `setwd()` commands. First, let us visualise the current default working directory.\n\n\n\n\n::: {.cell hash='main_body_cache/pdf/2.4_c6aca7eef8d7961298f0f60433290804'}\n\n```{.r .cell-code}\ngetwd()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"/home/piet/Dropbox/work/UKDS/RGuide/UKDS_RGuide\"\n```\n:::\n:::\n\n\n\n\nLet us say we would like the code from this guide to be all in a folder called ‘R_UKDS’, to be located in ‘My Documents’.  To tell R to use the folder ’R_UKDS, we can either create it from within Windows or ask R to do it for us.  So type: \n  \n  For Windows: \n  \n```\n> setwd(\"C:/Documents and Settings/<INSERT YOUR USERNAME HERE>/My Documents/R_UKDS\") \n```\nFor Mac:\n```\n> setwd(\"/Users/<INSERT YOUR USERNAME HERE>/Documents/R_UKDS\") \n```\nFor Linux:\n\n\n\n::: {.cell hash='main_body_cache/pdf/2.5_4729048e13771362fb9d08eceeedac69'}\n\n```{.r .cell-code}\ndir.create(\"~/Documents/R_UKDS\")\nsetwd(\"~/Documents/R_UKDS\")\n```\n:::\n\n\n\n\nTyping `getwd()`  confirms that the change has been recorded. \n\n\n\n\n::: {.cell hash='main_body_cache/pdf/2.6_759f69a77a94654e16372a7114dfdf31'}\n\n```{.r .cell-code}\ngetwd()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"/home/piet/Dropbox/work/UKDS/RGuide/UKDS_RGuide\"\n```\n:::\n:::\n\n\n\n\n**Notes:**\n  \n  - Any character string that is neither a command or the name of an object (such\n                                                                             as a variable name) needs to be put between inverted commas or quotation\nmarks, otherwise it will be interpreted as the name of an object\n- see the example below about loading user-created packages;\n\n- Even when no parameters are specified for a command, brackets are compulsory\nas shown in the `getwd()` example above;\n\n- R uses forward slashes rather than backslashes (unlike most other\n                                                  Windows applications) to separate directories. Using backlashes will return an\nerror message;\n- Although most R commands accept a large number of options to be specified,\nin many cases default values have been ‘factory set’ so that only the\nessential parameters need specifying.\n\nThe output of most R commands can be either directly displayed on the screen (as\n                                                                              in the above example) or stored in objects that can be subsequently reused in\nfurther commands. This object-oriented feature separates R from traditional\nstatistical software.\n\nFor instance, typing: \n  \n```\n>\ta<-getwd()\n```\n\nwill store the output of `getwd()`  (that is, the name of the current default directory)  into an object called ‘a’. In order to view the content of a, one can just type its name: \n```\n>\ta\n```\n\n\n<!-- Another approach to set a working directory is by creating an R Project. To learn more about why and how to set working directory in R and see how an R project is generated, see the “Setting a working directory” section in our Data Skills Module: Exploring crime surveys with R. -->\n  \n#### Writing R scripts  via R Studio {-}\n  Most users will want to write their code in a script file, similar to the ‘do’ file in Stata or syntax file in SPSS.  R script files end with the .R suffix. To open an existing  R script in RStudio select `File>Open File` then  the relevant script file. To create a new script  select `File>New File>Open File` (shortcut: Control+Shift+N) this will open a new script window in which to type commands.\n\n\n## Installing and loading packages\nApart from a basic set of commands and functions, most of the tools offered by R are available in packages that are not provided during the main installation and need to be installed and downloaded separately from within R. \nFor example, to install the ‘foreign’ package one need to type: \n  \n```\ninstall.packages(\"foreign\",repos = \"https://cloud.r-project.org\")\n```\n\nInstallation only needs to be done once. \nIf the address of the  package repository is not specified via the  `repos` option, a pull-down menu will appear, asking for one. Choosing `https://cloud.r-project.org` will automatically select the closest mirror site. \n\nOriginally, `Foreign`  enabled  users to import Stata (version 12 or older) or SPSS datasets. For  Stata datasets saved under version 13 and above, the `haven` or `readstata13` package are required. \n\n```\ninstall.packages(\"haven\",repos = \"https://cloud.r-project.org\")\n```\nTo use a package already  installed in  the local  R library,  the `library()` command is needed:\n  \n\n\n\n::: {.cell hash='main_body_cache/pdf/2.7_5420c536ccc052ca30e958735ba96509'}\n\n```{.r .cell-code}\nlibrary(foreign)\n```\n:::\n\n\n\n\nSimply typing: \n  \n```\n> library()\n```\nWill list all libraries installed on the computer that can be loaded in memory. This can be a rather long list!\n  \n  <!-- For users who feel more comfortable using ‘click-and-point', there is also the option to use ‘Install Packages’ from the Packages tab in the main R window. This will display a list of packages available in alphabetical order for the user to choose from. Next, select the desired package, double click on it and press ‘OK’ for the installation to begin. -->\n\nBesides a full archive of R packages, the CRAN website provides a series of manuals,  including [Writing R Extensions](https://cran.r-project.org/doc/manuals/R-exts.html), which describes how users can write their own packages and submit them to CRAN. \n\nOnce a package is installed, it will be permanently stored in the local R library on the computer, unless  deleted it with  the `remove.packages()` command (not advised as this can break dependencies between packages!).\n```\n> remove.packages(\"name of the package\")\n```\nPackages required  for an analysis have to be loaded every time a new R session is started (But not every time a syntax file is run!).  \n\n\n##  Getting help\nWithin R, the most straightforward way to request help with a command consists of a question mark followed by the command name, without a space in between.  The standard help system in R (unless using RStudio or Eclipse) relies on the default web browser installed on your computer (ie Chrome, Firefox or Edge in most cases) to display pages. \nTyping: \n\n```\n> ?getwd \n```\nIs equivalent of: \n```\nhelp('getwd')\n```\nand will open the help page for the `getwd()` command in the default web browser. If you are using RStudio or Eclipse, the help will most likely open in a new tab within the program. \n\nThis will work for any command directly available in the `Base` package that is loaded at startup or  in other packages loaded via the `library()` command. Otherwise, R will return an error message.\n\nTyping two question marks followed by a keyword will search all of R for the available documentation for that keyword:\n\n\n\n\n::: {.cell hash='main_body_cache/pdf/2.8_db3777467b3d21a68687d3f228146fa0'}\n\n```{.r .cell-code}\n ??foreign\n```\n:::\n\n\n\n\nAn index of all commands and functions in the foreign package can be obtained by typing:\n\n\n\n\n::: {.cell hash='main_body_cache/pdf/2.9_2e55371ff3714a522a047a469a2ae0b2'}\n\n```{.r .cell-code}\nhelp(package='foreign')\n```\n:::\n\n\n\nNote: this command only works because the ‘foreign’ package was previously loaded in memory with the `library()` command. More information about where to find help when using R is provided at the end of this document.\n\n\n\n\n## Objects\nR is an object oriented language, which means that almost any information it uses is stored as ‘objects’ (i.e. containers) that can be manipulated independently. During an R session, multiple objects are available simultaneously (for instance datasets, but also summary tables or new variables produced from it). \nTyping:\n```\n> ls()\n```\nwill list all the objects that are currently in memory.\n\nObjects belong to `classes` or types which have distinct `properties`. There are many classes of objects in R. By comparison, Stata has only macros, variables and scalars that are directly  available to most users. Common object classes include factors (these are equivalent to categorical variables), vectors (numerical variables – whether continuous or ordinal), data frames (datasets), matrices, etc. Not all operations are possible with all objects in R. More advanced users can also create their own object classes. Describing R objects and their properties is well beyond the purpose of this guide and users interested should consult the [online documentation](https://cran.r-project.org/doc/manuals/r-release/R-lang.html#Objects) for further explanations. \n\nTo create or assign a value to an object, one uses the assignment operator  (<-). For example:\n```\n> x <- 5 \n```\n\nIn this example we have assigned the value 5 to an object called x. If you type the letter x,  the value ‘5’ will be returned in your console. The object x will appear in the R environment after the ls() command. \n\n\n\n\n::: {.cell hash='main_body_cache/pdf/2.10_9240359ad27f64be823e5eeb41c36559'}\n\n```{.r .cell-code}\nx <- 5  \nx\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 5\n```\n:::\n\n```{.r .cell-code}\nls()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"has_annotations\" \"x\"              \n```\n:::\n:::\n\n\n\n\n#### Deleting objects  {-}\nThe rm() function can be used to remove objects from the environment (session). These objects can be variables, lists, datasets, etc. For instance, to remove the object ‘x’, or the fictitious dataset called ‘mydata’: \n\n\n\n\n::: {.cell hash='main_body_cache/pdf/2.11_477517de324c216c858e7e305a7b3439'}\n\n```{.r .cell-code}\nrm(x)\t\nls()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"has_annotations\"\n```\n:::\n:::\n\n\n\n\n```\n> rm(mydata)\n```\n<!-- The rm() function only works with R objects; but if you want to delete a specific variable of a dataset, you need a different function. For example, to delete the variable ‘age’ of the dataset ‘mydata’, an option is to set the variable to NULL:  -->\n\n<!-- > mydata$age<-NULL  -->\n\n<!-- There are other ways to delete variables from a dataset, but these will be looked at later on in this guide.  -->\n\n#### Data frames {-}\n\nAmong the various classes of objects one may use in R, a few are essential to understand when analysing survey data. Their characteristics are briefly listed below;\n\nData frames are  objects that come closest to datasets or excel sheets in traditional statistical software. They are objects that have indexed rows and columns, both of which may have names. Data frames  columns can be seen as  variables and lines or rows as observations. Each  cell in the data frame can be uniquely identified by its position. Data frames are typically the object in which survey datasets are stored.\n\n\n\n\n\n::: {.cell hash='main_body_cache/pdf/2.12_3ebb6cd1623900e83ac53800f7a2d210'}\n\n:::\n\n\n\n\nLet's assume that we have a  small data frame called 'mydata'. Here are  a few basic commands to examine it:\n  \n  **Determining the size of a data frame:** \n  the `dim()` command returns the number of rows and columns of a data frame\n\n\n\n\n::: {.cell hash='main_body_cache/pdf/2.13_2bfe480feb0893b233ae3a302904d9ea'}\n\n```{.r .cell-code}\ndim(mydata)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 50  6\n```\n:::\n:::\n\n\n\nR tells us that our data is made of 50 rows and 6 columns, in other words of 50 observations and 6 variables. What if I want a quick overview of the dataset?\n  \n\n\n\n::: {.cell hash='main_body_cache/pdf/2.14_432cd84401c759109aa92bcb88d7c4bb'}\n\n```{.r .cell-code}\nhead(mydata)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    RSex skipmeal                   Married\n1 Female       NA Married/living as married\n2 Female        1        Separated/divorced\n3 Female       NA Married/living as married\n4   Male       NA             Never married\n5   Male        1             Never married\n6   Male       NA Married/living as married\n        Poverty1                         HEdQual3\n1        Was not Higher educ below degree/A level\n2        Was not Higher educ below degree/A level\n3        Was not             O level or equiv/CSE\n4        Was not Higher educ below degree/A level\n5        Was not                 No qualification\n6 Was in poverty                             <NA>\n  NatFrEst\n1        5\n2       30\n3       50\n4       50\n5       50\n6       10\n```\n:::\n:::\n\n\n\nThe `head()` command displays the first  six lines of the dataset. Depending on the number of variables  the output of   `head()` can become quickly overwhelming, as the size of the lines on most screens is limited!\n  \n  **Obtaining the names of variables (or columns) in the dataset:**\n  This can be done using either  `ls()` which we already have used, or the `names()` commands. `ls()` returns the variables names, sorted alphabetically, whereas `names()` returns them in their actual order in the data frame.\n\n\n\n\n::: {.cell hash='main_body_cache/pdf/2.15_d1d25a9d775e9d83c51ec0d47b0208aa'}\n\n```{.r .cell-code}\nls(mydata)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"HEdQual3\" \"Married\"  \"NatFrEst\" \"Poverty1\"\n[5] \"RSex\"     \"skipmeal\"\n```\n:::\n\n```{.r .cell-code}\nnames(mydata)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"RSex\"     \"skipmeal\" \"Married\"  \"Poverty1\"\n[5] \"HEdQual3\" \"NatFrEst\"\n```\n:::\n:::\n\n\n\nWe can see that in the data frame, the \"RSex\" column comes in fact before \"Poverty1\".\n\n**Accessing variables:**\n  \n  Each column of a data frame, or variable, can be accessed by its name preceded by the $ sign: \n  \n\n\n\n::: {.cell hash='main_body_cache/pdf/2.16_aa00b8d5e4e1b9076640447f9130cb4a'}\n\n```{.r .cell-code}\nmydata$NatFrEst\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1]  5 30 50 50 50 10  1 NA  5 50 60 25 30  3 25 10 80\n[18]  5 50 50 40 45  2 82 60 40 10 10 40 15 30 30  2 10\n[35] 75 99 70 50 10 30  1 10 85 45 70 25 40 30 10 25\nattr(,\"value.labels\")\nnamed numeric(0)\n```\n:::\n:::\n\n\n\n\nAlternatively, columns/variables and rows can be identified numerically by their position in the data frame using square brackets: \n```\ndataframe[row number,column number]\n```\nGiven that `RSex` is the first column of our dataset\n\n\n\n\n::: {.cell hash='main_body_cache/pdf/2.17_313d3c157dad02eb57066194631adcac'}\n\n```{.r .cell-code}\nmydata[,1]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] Female Female Female Male   Male   Male   Male  \n [8] Female Male   Male   Male   Female Female Male  \n[15] Female Female Female Female Female Female Male  \n[22] Female Female Male   Male   Female Female Female\n[29] Female Male   Female Female Female Female Male  \n[36] Male   Female Female Male   Female Male   Male  \n[43] Female Male   Female Male   Female Female Female\n[50] Male  \nLevels: Male Female\n```\n:::\n:::\n\n\n\nReturns the same output as previously. Not specifying a row or column name within the square brackets tells R to display them all.   \n\n\n\n\n::: {.cell hash='main_body_cache/pdf/2.18_f6e50e2567ff37bd184ca17395149da9'}\n\n```{.r .cell-code}\nmydata[6,]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  RSex skipmeal                   Married\n6 Male       NA Married/living as married\n        Poverty1 HEdQual3 NatFrEst\n6 Was in poverty     <NA>       10\n```\n:::\n:::\n\n\n\nReturns the values of all the variables for the sixth row of the data frame. Specifying both a row and column number, will return a unique observation: \n  \n\n\n\n::: {.cell hash='main_body_cache/pdf/2.19_fcd879f431e8e4dc75f83ddfc1411da1'}\n\n```{.r .cell-code}\nmydata[6,6]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 10\n```\n:::\n:::\n\n\n\nwhich in this case is 10. \nFinally, more than one column or row can be displayed by concatenating their number using the `c()` function:\n  \n\n\n\n::: {.cell hash='main_body_cache/pdf/2.20_58794cba0a4a31e894523423231021d6'}\n\n```{.r .cell-code}\nmydata[c(6,9),c(1,6)]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  RSex NatFrEst\n6 Male       10\n9 Male        5\n```\n:::\n:::\n\n\n\nThe above command returns respectively the sixth and 9th observations for the  sixth column. Please note that columns names can also be used instead of their number, provided that they are put between inverted commas:\n  \n\n\n\n::: {.cell hash='main_body_cache/pdf/2.21_b4d2e184d7cc1e213b258eb1dbb4129b'}\n\n```{.r .cell-code}\nmydata[c(6,9),c('RSex','NatFrEst')]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  RSex NatFrEst\n6 Male       10\n9 Male        5\n```\n:::\n:::\n\n\n\nReturns the same result as previously.\nHaving a data frame to hand allows us to explore other types of objects commonly found in R. The type of a variable can  be displayed  by simply using the `class()` function. \n\n#### Numeric {-}\n\n`Numeric` objects are simple numerical vectors (ie a single or a list of numbers). Here this is the case for `NatFrEst`, the estimated proportion of people making wrong benefits claims, according to respondents to the survey.  \n\n\n\n::: {.cell hash='main_body_cache/pdf/2.22_6520f4e1a62fcf5fed5039c74558a8f8'}\n\n```{.r .cell-code}\nclass(mydata$NatFrEst)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"numeric\"\n```\n:::\n:::\n\n\n\n#### Character {-}\nCharacter objects are alphanumeric vectors, that is variables which consist of text string(s).\n\n\n\n::: {.cell hash='main_body_cache/pdf/2.23_d286491d4a236576fc860371b00c4c83'}\n\n```{.r .cell-code}\nclass(mydata$Married)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"character\"\n```\n:::\n:::\n\n\n\n#### Factors {-}\nAn important feature of R is that categorical variables whether ordinal or polynomial are stored in objects known as **factors**. The main difference between factors and traditional categorical variables in Stata or SPSS is that they do **not** consist of discrete numerical values with which value labels are associated. They should be thought of instead as a special type of character variable with a discrete set of values, which are known as `levels`. In our data, `Rsex` (Gender of the respondent) is such an object:   \n\n\n\n::: {.cell hash='main_body_cache/pdf/2.24_70d835ef02e9a45b3bce3971f8e7ec29'}\n\n```{.r .cell-code}\nclass(mydata$RSex)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"factor\"\n```\n:::\n:::\n\n\n\nLet's further examine this factor.\n\n\n\n\n::: {.cell hash='main_body_cache/pdf/2.25_b8d9c5b6bef4cf19eda43332950f5c96'}\n\n```{.r .cell-code}\nlevels(mydata$RSex)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Male\"   \"Female\"\n```\n:::\n:::\n\n\n\nreturns the levels (ie the values) of  `RSex`. Even if 'Male' is the first level of `Rsex`,\nand female the second one, these do not correspond to underlying numbers in the\ndata. Please also note that it is possible to change the ordering of factor\nlevels with the `factor()` function. It is always a good idea to check the ordering of factor levels in a newly created variable. \n\n\n\n\n::: {.cell hash='main_body_cache/pdf/2.26_9baa2494f4d5a0bc467819bba580808e'}\n\n```{.r .cell-code}\nmydata$RSex.New<-factor(mydata$RSex,levels = levels(mydata$RSex)[c(2,1)])\nlevels(mydata$RSex.New)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Female\" \"Male\"  \n```\n:::\n:::\n\n\n\nThe above code tells R to create a new factor variable -`RSex.New` - whose levels are the same as the initial `RSex`, but with  'Female' coming first, and \"Male\", second. The name of the new variable is arbitrary.\n\n\n\\newpage                                            \n\n# Opening UKDS datasets in R\n## Essential information\nIn principle, any  dataset whether in CSV, SPSS, SAS, or Stata format can be opened by R. There are a number of issues to consider however:\n\n  - The `foreign` package has been traditionally used  to import SPSS and Stata datasets into R:\n  \n    - its `read.spss()` and `write.spss()` functions respectively open and write .sav files. Given that both were developed from  older versions of SPSS, it is therefore advised  to check that their outcome is as expected. In addition:\n      - `read.spss()` does not store the data in a R data frame by default and will require the option         `to.data.frame=T` to be specified.\n      - `read.spss()` may sometimes struggle with some numeric format and wrongly attempt to convert them as factor, which will result in error messages. It is therefore advised to limit the maximum number of levels that  will be considered when converting factors  by using  the option   `max.value.labels=`\n\n    - `read.dta()` and `write.dta()` respectively open and write Stata files up to version 12. An option to watch for is `convert.factor=T/F` which either will import  Stata categorical variable as their underlying numeric value or instead will convert them into factors, using value labels as levels, which may be an issue for categorical variables with a large number of levels. Users have to bear in mind that the labels will by default sorted alphabetically.\n    \n  - The `readstata13` package opens  Stata datasets from version 13 onwards with the `read.dta13()` function and offers a more comprehensive set of options. `convert.factor=T/F` has the same effect as in  `read.dta()` from `foreign`.\n  - Data frames created with either `read.dta()` or `read.dta13()` have extra information stored as attributes, which maybe useful to retrieve. For instance:\n```\n> mydata<-read.dta(\"Some_Stata_dataset.dta\")\n> attributes(mydata)$var.labels ### Retrieves the original Stata variable labels\n```\n\n- Finally the `haven` package opens SPSS, Stata and SAS files with respectively `read_spss()`, `read_dta()` and `read_sas()`. By contrast with the other two packages, it relies on ad hoc data formats and data structures for converting labelled categorical variables and attempts to mimic Stata's value and variable labels. More information is available [here](https://haven.tidyverse.org/reference/read_dta.html).\n\nIn order not to overcomplicate their initial exploration of R we recommend new users to use  `read.spss()` or `read.dta13()` when importing datasets from either SPSS or Stata, rather than the more elaborate functions available in `haven`.\n\n\n\n## The 2017 British Social Attitudes Survey\nFor the rest of this guide, we will use the `British Social Attitudes Survey, 2017, Environment and Politics: Open Access Teaching Dataset`, which can be downloaded from the [UK Data Service website](https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=8849). We will use  the   SPSS version of the dataset, which will be assumed to be  saved in a `UKDS` folder created inside `Documents` folder. `C:\\\\Users\\\\Your_User_Name_Here\\\\Documents` We will  set this as default working directory. This way, we won’t have to specify the full path of files that we will be opening or saving.  \n\n\n\n\n::: {.cell hash='main_body_cache/pdf/3.1_e071f2164716be37f488bbb9955ffdb6'}\n\n:::\n\n\n\n\nWe can finally open the file:\n  \n\n\n\n::: {.cell hash='main_body_cache/pdf/3.2_2cb2b7f92cd93757fe7bda68d8023e93'}\n\n```{.r .cell-code}\nbsa<-read.spss(paste0(datadir,\"8849spss_V1/bsa2017_open_enviropol.sav\"), \n               to.data.frame = TRUE,\n               use.value.labels=TRUE,\n               max.value.labels = 9)  \n\ndim(bsa)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 3988   25\n```\n:::\n:::\n\n\n\n##  Understanding the dataset\nAs previously, we can find the number of observations and variables in the dataset by typing the following:\n  \n\n\n\n::: {.cell hash='main_body_cache/pdf/3.3_036c531871e57563b18b916445564aa5'}\n\n```{.r .cell-code}\ndim(bsa)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 3988   25\n```\n:::\n:::\n\n\n\n\nWe can see that there are 3,988 observations and 25 variables in the BSA dataset.\n\nTyping:\n\n\n\n::: {.cell hash='main_body_cache/pdf/3.4_fffb71cd8766dc6ec0c0d7cf33523b3e'}\n\n```{.r .cell-code}\nls()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"bsa\"             \"datadir\"        \n[3] \"has_annotations\" \"mydata\"         \n```\n:::\n:::\n\n\n\n\nwill show us that the object ‘bsa’ has appeared, but what if we want to get the list of all variables in the dataset?  We need to type:\n\n\n\n::: {.cell hash='main_body_cache/pdf/3.5_9786e52d1f86f86ab3a699b8401aef1d'}\n\n```{.r .cell-code}\nls(bsa)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"actchar\"          \"actpol\"          \n [3] \"carallow\"         \"carenvdc\"        \n [5] \"carnod2\"          \"carreduc\"        \n [7] \"cartaxhi\"         \"CCBELIEV\"        \n [9] \"ChildHh\"          \"eq_inc_quintiles\"\n[11] \"govnosa2\"         \"HEdQual3\"        \n[13] \"leftrigh\"         \"libauth\"         \n[15] \"Married\"          \"PartyId2\"        \n[17] \"plnenvt\"          \"plnuppri\"        \n[19] \"Politics\"         \"RAgeCat\"         \n[21] \"RClassGp\"         \"Rsex\"            \n[23] \"Sserial\"          \"Voted\"           \n[25] \"WtFactor\"        \n```\n:::\n:::\n\n\n\n\nIf we want to get a better sense of the data, we use the `head()`  function which will return the first six rows.\n\n\n\n::: {.cell hash='main_body_cache/pdf/3.6_123d534e2d78f15f506e26f87815f221'}\n\n```{.r .cell-code}\nhead(bsa)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Sserial   Rsex RAgeCat                   Married\n1  290001   Male   35-44 Married/living as married\n2  290002 Female     65+        Separated/divorced\n3  290003 Female   45-54 Married/living as married\n4  290004 Female   45-54 Married/living as married\n5  290005   Male     65+             Never married\n6  290006 Female   25-34             Never married\n  ChildHh                         HEdQual3\n1     Yes             O level or equiv/CSE\n2      No Higher educ below degree/A level\n3     Yes                           Degree\n4     Yes                           Degree\n5      No Higher educ below degree/A level\n6     Yes Higher educ below degree/A level\n                           eq_inc_quintiles\n1 3rd quintile - More than £292, up to £404\n2                                      <NA>\n3 3rd quintile - More than £292, up to £404\n4 3rd quintile - More than £292, up to £404\n5 4th quintile - More than £404, up to £577\n6              Lowest quintile - Up to £175\n                                   RClassGp\n1 Lower supervisory & technical occupations\n2        Semi-routine & routine occupations\n3          Managerial & professional occups\n4          Managerial & professional occups\n5          Managerial & professional occups\n6          Managerial & professional occups\n                                                                                          CCBELIEV\n1               I believe that climate change is taking place but not as a result of human actions\n2 I believe that climate change is taking place and is, at least partly, a result of human actions\n3                                                                                             <NA>\n4                                                                                             <NA>\n5                                                                                             <NA>\n6                                                                                             <NA>\n  carallow carreduc carnod2 cartaxhi carenvdc plnenvt\n1     <NA>     <NA>    <NA>     <NA>     <NA>    <NA>\n2     <NA>     <NA>    <NA>     <NA>     <NA>    <NA>\n3     <NA>     <NA>    <NA>     <NA>     <NA>    <NA>\n4     <NA>     <NA>    <NA>     <NA>     <NA>    <NA>\n5     <NA>     <NA>    <NA>     <NA>     <NA>    <NA>\n6     <NA>     <NA>    <NA>     <NA>     <NA>    <NA>\n  plnuppri          Politics Voted\n1     <NA>             some,   Yes\n2     <NA> ... a great deal,   Yes\n3     <NA>             some,   Yes\n4     <NA> ... a great deal,   Yes\n5     <NA>    not very much,   Yes\n6     <NA>    not very much,   Yes\n                actchar                actpol\n1                 never                 never\n2                  <NA>                  <NA>\n3                  <NA>                  <NA>\n4 once in the past year once in the past year\n5                  <NA>                  <NA>\n6                  <NA>                  <NA>\n                    govnosa2         PartyId2 leftrigh\n1                      agree           Labour      1.0\n2                   disagree           Labour      1.8\n3                       <NA>           Labour       NA\n4                      agree           Labour      1.5\n5                       <NA> Liberal Democrat      2.0\n6 neither agree nor disagree             <NA>      3.0\n  libauth WtFactor\n1   4.500   0.9381\n2   4.333   0.6844\n3      NA   0.9061\n4   2.500   1.3086\n5   3.167   0.4393\n6   3.000   0.5696\n```\n:::\n:::\n\n\n\n\n\n\nSingle variables for example, `Rsex` (gender of respondents) may be also summarised with `head()`, which returns as previously the first six observations of the gender variable, whereas typing  \n\n\n\n\n\n::: {.cell hash='main_body_cache/pdf/3.7_0e2ae0b315a2528c4fa6bc8097a44954'}\n\n```{.r .cell-code}\nhead(bsa$Rsex)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] Male   Female Female Female Male   Female\nLevels: Male Female\n```\n:::\n:::\n\n\n\nSimply typing the name of a variable as in:  \n```\nbsa$Rsex\n```\nwill list the first 1000 observations of the variable.  Other commands provide more useful information, such as `summary()`.  \n\n\n\n\n::: {.cell hash='main_body_cache/pdf/3.8_1fdc08cfdafbbf4b0fb6c1689a153cc6'}\n\n```{.r .cell-code}\nsummary(bsa$Rsex)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Male Female \n  1806   2182 \n```\n:::\n:::\n\n\n\n\nSummary is a generic function that tailors the most appropriate output  to an object class. As Rsex is a categorical variable. The output of summary() is identical to what we would have obtained with the default tabulation fuction `table()`:\n  \n\n\n\n::: {.cell hash='main_body_cache/pdf/3.9_218cc7a37a44b512ad5b9da165a92962'}\n\n```{.r .cell-code}\ntable(bsa$Rsex)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n  Male Female \n  1806   2182 \n```\n:::\n:::\n\n\n\n\nWhen encountering a continuous variable, `summary()` will compute  basic descriptive statistics (mean, median, quartiles, maximum and minimum). For example, in the case of the libertarian-authoritarian scale `libauth`:  \n  \n\n\n\n::: {.cell hash='main_body_cache/pdf/3.10_539054e2e095ec14c091f61f594d8816'}\n\n```{.r .cell-code}\nsummary(bsa$libauth)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    1.2     3.0     3.5     3.5     4.0     5.0 \n   NA's \n    775 \n```\n:::\n:::\n\n\n\n\n\n##  Identifying and selecting variables\nAs we have already seen, variables are objects. R automatically stores variables using the appropriate object class. Categorical variables are ‘Factors’ with ‘Levels’ as categories within these, while continuous variables are ‘Numeric’ types of objects.\nThe `class()` displays the type of an object:.\n\n\n\n\n::: {.cell hash='main_body_cache/pdf/3.11_5b94da94389c4cbd3ce1a62a0677107c'}\n\n```{.r .cell-code}\nclass(bsa$Rsex)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"factor\"\n```\n:::\n:::\n\n\n\n\nThe levels() function returns the categories of the variable.\n\n\n\n::: {.cell hash='main_body_cache/pdf/3.12_4e2d6ecfbc33c0aa16402157266d0c6e'}\n\n```{.r .cell-code}\nlevels(bsa$Rsex)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Male\"   \"Female\"\n```\n:::\n:::\n\n\n\n\\newpage\n\n# Essentials of Data Manipulation\nIn this section we will cover  how to recode variables and deal with missing data.\n\n## Creating and transforming numerical variables\nLet's say we would like to transform  our numerical political orientation variable: `leftrigh` into a logarithmic scale. We can use the `log()` function  which is directly available in R Base package and simply  returns the natural logarithm (base-e). We will  use the assignment operator ( <- ) to create a new variable called ‘leftright_log’ from the original variable\n\n\n\n\n::: {.cell hash='main_body_cache/pdf/4.1_0e1ed7a2386ccd412e0e18624d1b54b7'}\n\n```{.r .cell-code}\nbsa$lnleftrigh_log <- log(bsa$leftrigh)\n```\n:::\n\n\n\n\nNote that if we had not specified `bsa$` the command would have created a transformed variable outside of the BSA data frame. We can now check the results with `summary()`\n\n\n\n\n::: {.cell hash='main_body_cache/pdf/4.2_630dc1938cc2b6c5580355d59dca4a51'}\n\n```{.r .cell-code}\nsummary(cbind(bsa$lnleftrigh,bsa$leftrigh))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       V1            V2     \n Min.   :0.0   Min.   :1.0  \n 1st Qu.:0.7   1st Qu.:2.0  \n Median :0.9   Median :2.4  \n Mean   :0.9   Mean   :2.5  \n 3rd Qu.:1.1   3rd Qu.:3.0  \n Max.   :1.6   Max.   :5.0  \n NA's   :782   NA's   :782  \n```\n:::\n:::\n\n\n\nPlease note that it is not possible to pass several variables names directly to `summary()`. We need to group them first into a temporary object using `cbind()`. In the output `V1` refers to the first variable, `lnleftrigh`.\n\nWhat if we - hypothetically - wanted to do the same with level of agreement to the statement \"People like me don`t have any say about what the government does\", a categorical variable, originally ranging from  1 (`Agree strongly`) to 5 (`Disagree strongly`)? If we try to repeat what we did before:\n\n\n\n\n::: {.cell hash='main_body_cache/pdf/4.3_8fb193f8798f7a5215f4ce966111d68a'}\n\n```{.r .cell-code}\nbsa$lngovnosa2 <- log(bsa$govnosa2)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in Math.factor(bsa$govnosa2): 'log' not meaningful for factors\n```\n:::\n:::\n\n\n\n... we get an error, due to the fact that `govnosa2` was imported as a factor, and that `log()` can only be applied to numeric objects.\n\n\n\n\n\n::: {.cell hash='main_body_cache/pdf/4.4_675d5f61a21437a6022d7e58f460b068'}\n\n```{.r .cell-code}\nclass(bsa$govnosa2)       #check to see if it is numeric\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"factor\"\n```\n:::\n\n```{.r .cell-code}\nbsa$govnosa2.n <- as.numeric(bsa$govnosa2)#convert to numeric \nclass(bsa$govnosa2.n)       #check again\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"numeric\"\n```\n:::\n\n```{.r .cell-code}\nbsa$lngovnosa2 <- log(bsa$govnosa2.n) #create new log of the leftright      variable \nsummary(cbind(bsa$lngovnosa2,bsa$govnosa2.n))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       V1             V2      \n Min.   :0.0    Min.   :1.0   \n 1st Qu.:0.7    1st Qu.:2.0   \n Median :1.1    Median :3.0   \n Mean   :0.9    Mean   :2.7   \n 3rd Qu.:1.4    3rd Qu.:4.0   \n Max.   :1.6    Max.   :5.0   \n NA's   :2447   NA's   :2447  \n```\n:::\n:::\n\n\n\n\n  We can also create a completely new variable in the dataset. For instance, the following will create  `test` with a constant value of 1.\n\n\n\n\n::: {.cell hash='main_body_cache/pdf/4.5_d23f65dbf9b702745bb3d54a31507013'}\n\n```{.r .cell-code}\nbsa$test <- 1\n```\n:::\n\n\n\n\n## Categorical variables\nWe saw in Section 3 that  categorical variables are objects called **factors** in R, with a fixed set of possible  numerical or alphanumerical values (levels) which  can be  accessed with the `levels()` function.\n\n\n\n\n::: {.cell hash='main_body_cache/pdf/4.6_1051d052b36c51431305288a1439eff4'}\n\n```{.r .cell-code}\nlevels(bsa$Married) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Married/living as married\"\n[2] \"Separated/divorced\"       \n[3] \"Widowed\"                  \n[4] \"Never married\"            \n```\n:::\n:::\n\n\n\nThe number in the output does not refer to  underlying numerical values to which  labels are added as with other statistical packages, but instead to the position of a given level in the list returned by `level()`.\n\n\n## Recoding variables\n The following commands will create a new variable called `Married2` where respondents  are categorised into two new categories: 'Not partnered' and 'Partnered'. The \"separated/divorced” and “Never married”  categories of the “Married” variable are recoded as  “Not partnered”. It is always advised to create new variables when recoding old ones so the original data is not tampered with.\n \n\n\n\n::: {.cell hash='main_body_cache/pdf/4.7_d801a35ef5f4c99c9250d076f914a5e2'}\n\n```{.r .cell-code}\nbsa$Married2 <- ifelse(bsa$Married==\"Married/living as married\",\"Partnered\",bsa$Married)\nbsa$Married2 <- ifelse(bsa$Married==\"Widowed\" | \n                       bsa$Married==\"Never married\" | \n                      bsa$Married==\"Separated/divorced\",\"Not partnered\",bsa$Married2)\n\ntable(bsa$Married2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nNot partnered     Partnered \n         1778          2209 \n```\n:::\n:::\n\n\n\nThe second and fourth categories have been renamed to ‘Not partnered’. Now we\nhave two levels\n    * Partnered\n    *Not partnered\n\n`ifelse()` is  a convenient tool to use when it is required to work with Base R or when the variables have a limited number of categories. More complex cases may require a more advanced function. The `dplyr` library provides a comprehensive set of data manipulation tools.\n\n\n\n\n\n::: {.cell hash='main_body_cache/pdf/4.8_e5c17986ad7a0766515db09ea5f6e3d5'}\n\n```{.r .cell-code}\nlibrary(dplyr)\nbsa<-bsa%>%\n     mutate(Married3=case_when(\n               Married == \"Married/living as married\" ~ \"Partnered\",  \n               Married == \"Separated/divorced\" | Married == \"Widowed\" ~ \"Not Partnered\",\n               Married == \"Never married\" ~ \"Not Partnered\"\n)\n)\nbsa$Married3<-as.factor(bsa$Married3)\nsummary(bsa$Married3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNot Partnered     Partnered          NA's \n         1778          2209             1 \n```\n:::\n:::\n\n\n\nWe just created the `Married3` variable, which is identical to `Married2` above, but using the more powerful syntax made available by `dplyr`. Let's decompose it:\n\n- `dplyr` use the `pipe` symbol ie `%>%` which enables to sequentially combine functions. We will come back to this later in this guide. \n- `mutate()` is the generic variable creation/alteration command, and can handle complex combinations of conditions as well as multiple simultaneous variable creation operations.\n- `case_when()` is the function that allows recoding numerical, character, or factor variables. On the left hand side of the tilde `~` are the condition or the  values that need to be matched in the original variable , and on the right hand side, the  attributed ie recoded values in the new variable. Note that in this case, the recoded variable is by default a character object and needs to be converted into a factor for easier manipulation. \n\n**Extra tips:**\n\n- As with any data manipulation exercise, caution is required, and it is recommended to create new variables with the recoded value rather than alter an original variable when handling missing values.\n- The standard value attribution command in R is `<-`. However, `=` will also work in many cases.\n- Unless explicitly specified (in our case, by adding the bsa$ prefix to variable name), the objects created are not included in the data frame from which they were computed. \n\n## Missing Values\nExplicit missing values in R (ie values that R itself considers as missing) are represented as `NA` for factors and numerical variables. For character variables, missing values are simply empty strings, ie `\"\"`. R has a series of functions specifically designed to handle NAs.\n\nR has fewer safety nets than other packages for handling missing values. Most function won't issue  warn users about whether or how many how many observations with missing values have been dropped. On the other hand, some commands will return error messages and won't run when  missing values are present. This is the case of `mean()` for example.  \n\n### Inspecting missing data\n\nThe logical function `is.na()` assesses each observation in variables and identifies whether  cases are valid or missing. The result will appear as a boolean  TRUE/FALSE vector for each observation. `is.na()` can be  combined  with other functions:\n\n- With `table()` in order to get the frequencies of missing values of a specific variable.   \n\n- With sum() in order to count the number of missing observations of variables or whole datasets.  \n\n\n\n\n::: {.cell hash='main_body_cache/pdf/unnamed-chunk-1_8722c40082d86dfb2ea2ed1d9a1bfcdf'}\n\n```{.r .cell-code}\ntable(is.na(bsa$leftrigh))#of missing values in the leftright variable \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nFALSE  TRUE \n 3206   782 \n```\n:::\n\n```{.r .cell-code}\nsum(is.na(bsa)) # of missing values in the whole dataset\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 41486\n```\n:::\n\n```{.r .cell-code}\nmean(is.na(bsa$leftrigh)) #returns the proportion of NAs...\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.1961\n```\n:::\n\n```{.r .cell-code}\nmean(is.na(bsa)) # returns the proportion in the dataset\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.3356\n```\n:::\n:::\n\n\n\n\n### Recoding missing values as NA (continuous variables)\nIt may sometimes be useful to  recode implicit  missing values (ie  considered by the data producer as missing, but not by R)  of either numeric objects or factors into  `<NA>`,  in order to simplify case selection when conducting analyses.  This can either be done with Base R code or  the more advanced data manipulation functions from the dplyr package that we explored earlier.\n\nLet's assume for a moment  that we would like to get rid of respondents aged under 25 for our analysis. A safe way to proceed is by creating a new variable. \n\n\n\n\n::: {.cell hash='main_body_cache/pdf/4.9_2a5f5a9c751ee3d88ff7f53175f15d0e'}\n\n```{.r .cell-code}\nbsa$RAgeCat2 <- bsa$RAgeCat #duplicate variable\ntable(bsa$RAgeCat2)                      \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n18-24 25-34 35-44 45-54 55-59 60-64   65+ \n  223   591   650   729   320   333  1138 \n```\n:::\n\n```{.r .cell-code}\nbsa$RAgeCat2[bsa$RAgeCat2==\"18-24\" ] <- NA #convert responses “18-24”  to NA\ntable(bsa$RAgeCat2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n18-24 25-34 35-44 45-54 55-59 60-64   65+ \n    0   591   650   729   320   333  1138 \n```\n:::\n\n```{.r .cell-code}\ntable(is.na(bsa$RAgeCat2))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nFALSE  TRUE \n 3761   227 \n```\n:::\n:::\n\n\n\nWhy is the number of missing values 227 and not 223 as the original number of respondents aged 18-24? Because there were already 3 missing values for the RAgeCat variable.  \n\nWe can also notice that although there are now no observation left in the 18-24 category, it is still displayed by `table()`. This is because  levels are attributes of factors and are not deleted with observations. We can remove unused levels permanently with `droplevels()`   \n\n\n\n\n::: {.cell hash='main_body_cache/pdf/4.10_8ff5d90c4b35e547bf70a9926b0ed256'}\n\n```{.r .cell-code}\nbsa$RAgeCat2<-droplevels(bsa$RAgeCat2)\ntable(bsa$RAgeCat2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n25-34 35-44 45-54 55-59 60-64   65+ \n  591   650   729   320   333  1138 \n```\n:::\n:::\n\n\n\n### Working with missing values\nExplicit missing values (coded as NA) can be taken care of by R’s own missing values functions. For instance using the `na.rm=T` or `na.rm=TRUE` option will remove  missing values from an analysis (typing `?na.rm` will provide more information). Below is a summary of how NAs are dealt with by common R commands:\n\n\n\n\n\n::: {.cell hash='main_body_cache/pdf/4.11_944cea737d0f2871911fec6f26a0675a'}\n::: {.cell-output-display}\nTable: Treatment of missing values by R commands\n\n|Command                 |Default action                    |Parameter                         |\n|:-----------------------|:---------------------------------|:---------------------------------|\n|*mean(), sd(),median()* |Includes NA (may return an error) |na.rm=T                           |\n|*cor(),cov()*           |Includes NA (may return an error) |*use=\"complete.obs\"*              |\n|*table()*               |Excludes NA                       |*useNA = \"always\"* to display NAs |\n|*xtabs()*               |Excludes NA                       |*addNA = T* to display NAs        |\n|lm(),glm()              |Excludes NA                       |*na.action=NULL*                  |\n:::\n:::\n\n\n\n\n\n## Subsetting datasets\nWhen analysis survey data. it is often necessary to limit the scope of computation to specific groups or subset of the data we may be interested in. There are many ways of subsetting datasets in R. We will review the most common here.  \n\n**Using Base R**\n\nMost subsetting commands involve some form of conditions whereby the characteristics of a subsample of interest are specified. Suppose we would like to examine  the interest for politics among people aged 18-24. \n\nWe can either create an adhoc data frame:\n\n\n\n\n::: {.cell hash='main_body_cache/pdf/4.12_90b2408da4d8402713c0ebfb7644cb66'}\n\n```{.r .cell-code}\ntable(bsa$Politics)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n... a great deal,      quite a lot,             some, \n              739               982              1179 \n   not very much,  or, none at all? \n              708               379 \n```\n:::\n\n```{.r .cell-code}\nbsa.young<-bsa[bsa$RAgeCat==\"18-24\",]  \ntable(bsa.young$Politics)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n... a great deal,      quite a lot,             some, \n               29                41                72 \n   not very much,  or, none at all? \n               56                25 \n```\n:::\n\n```{.r .cell-code}\nbsa.young<-bsa[bsa$RAgeCat==\"18-24\",]\n```\n:::\n\n\n\nOr we can directly limit the extent of the analysis on the go:\n\n\n\n\n::: {.cell hash='main_body_cache/pdf/4.13_2d86c715c17ccf6003232864a3605598'}\n\n```{.r .cell-code}\n  table(bsa$Politics[bsa$RAgeCat==\"18-24\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n... a great deal,      quite a lot,             some, \n               29                41                72 \n   not very much,  or, none at all? \n               56                25 \n```\n:::\n:::\n\n\n\nIn the first example it was necessary to include a comma after specg the condition. This is meant to indicate that we want to retain all variables ie columns in the dataset. The comma is not necessary in the second example as we are already working with a single variable.\n\n**Using dplyr***\n\nNow suppose we want to further restrict the analysis to people  identifying as Males. We could use the same Base R syntax as above, but with more than one condition coding tends to become cumbersome. We could instead use the more convenient syntax from the `dplyr` package. Either: \n\n\n\n\n::: {.cell hash='main_body_cache/pdf/4.14_e3a647f2b642298a3466d8eaeee0bec4'}\n\n```{.r .cell-code}\nbsa.young.males<-bsa%>%filter(RAgeCat==\"18-24\" & Rsex==\"Male\")  \ntable(bsa.young.males$Politics)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n... a great deal,      quite a lot,             some, \n               15                22                30 \n   not very much,  or, none at all? \n               18                 9 \n```\n:::\n:::\n\n\n\n\nOr. as before embed it as a condition within `table()` :\n\n\n\n::: {.cell hash='main_body_cache/pdf/4.15_fc038eb7e1a6b261d348ee70fb570d41'}\n\n```{.r .cell-code}\n  table(bsa%>%filter(RAgeCat==\"18-24\" & Rsex==\"Male\")%>%select(Politics) )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPolitics\n... a great deal,      quite a lot,             some, \n               15                22                30 \n   not very much,  or, none at all? \n               18                 9 \n```\n:::\n:::\n\n\n\n\nWe are now equipped with the necessary information to move to the next stage and carry out basic analysis using R.\n\n\\newpage\n\n\n# Descriptive statistics\n## Continuous variables \no\nProducing descriptive statistics in R is relatively straightforward, as key functions are included by default in the Base package. We have already seen above that the `summary()` command provides essential information about a variable. For instance,\n\n\n\n::: {.cell hash='main_body_cache/pdf/5.1_1e96ed08e5db55e0b332dd006525c02c'}\n\n```{.r .cell-code}\nsummary(bsa$leftrigh)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   1.00    2.00    2.40    2.52    3.00    5.00     782 \n```\n:::\n:::\n\n\n\nprovides  information about the mean, median and quartiles of the political scale of respondents.\n\nThe `describe()` command from  the `Hmisc` package provides a more detailed set of summary statistics. \n\n\n\n::: {.cell hash='main_body_cache/pdf/5.2_afbeba46527d81e789a1b434226f7f4f'}\n\n```{.r .cell-code}\nlibrary(Hmisc)\ndescribe(bsa$leftrigh)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nbsa$leftrigh \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n    3206      782       30    0.993     2.52   0.8831      1.2      1.4 \n     .25      .50      .75      .90      .95 \n     2.0      2.4      3.0      3.6      4.0 \n\nlowest : 1    1.2  1.4  1.5  1.6 , highest: 4.4  4.6  4.75 4.8  5   \n```\n:::\n:::\n\n\n\n`describe()` also provides the number of observations (including missing and unique observations), deciles as well as the five largest and smallest values.\n\nCommands producing single  statistics are also available:\n  \n\n\n\n::: {.cell hash='main_body_cache/pdf/5.3_63ef3b012332e3ee7fc32a7f50366bb8'}\n\n```{.r .cell-code}\nmean(bsa$leftrigh, na.rm = T)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2.519911\n```\n:::\n\n```{.r .cell-code}\nsd(bsa$leftrigh, na.rm = T)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.7852958\n```\n:::\n\n```{.r .cell-code}\nmedian(bsa$leftrigh, na.rm = T)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2.4\n```\n:::\n\n```{.r .cell-code}\nmax(bsa$leftrigh, na.rm = T)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 5\n```\n:::\n\n```{.r .cell-code}\nmin(bsa$leftrigh, na.rm = T)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1\n```\n:::\n:::\n\n\n\n\nWe could  combine the output from the above commands into a single line using the `c()` function:\n\n\n\n::: {.cell hash='main_body_cache/pdf/5.4_8aec1dad56e49146a637bee545fa3531'}\n\n```{.r .cell-code}\nc(\n  mean(bsa$leftrigh, na.rm = T),\n  sd(bsa$leftrigh, na.rm = T),\n  median(bsa$leftrigh, na.rm = T),\n  max(bsa$leftrigh, na.rm = T),\n  min(bsa$leftrigh, na.rm = T)\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2.5199106 0.7852958 2.4000000 5.0000000 1.0000000\n```\n:::\n:::\n\n\n\n\nAs we saw previously, the `na.rm = T` option prevents missing values from being taken into account (in which case the output would have been NA, as this is the default behaviour of these functions). Using these individual commands may come in handy, for instance when further processing of the result is needed:\n  \n\n\n\n::: {.cell hash='main_body_cache/pdf/5.5_fedebbfadc2f4011d07e5d64b0ec0def'}\n\n```{.r .cell-code}\nm <- mean(bsa$leftrigh, na.rm= T)\n```\n:::\n\n\n\n\nLet’s round the results to two decimal places:\n\n\n\n::: {.cell hash='main_body_cache/pdf/5.6_3bd56f178d5bef89e62cfc485815ad84'}\n\n```{.r .cell-code}\nrm <- round(m,2)\n```\n:::\n\n\n\n\nWe can see the final results by typing:\n\n\n\n::: {.cell hash='main_body_cache/pdf/5.7_ec82a2a98a3b876f8232fa741b4615a1'}\n\n```{.r .cell-code}\nrm\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2.52\n```\n:::\n:::\n\n\n\n\nNote: \n\n\n\n::: {.cell hash='main_body_cache/pdf/5.8_19298b54e04bde275a7cb21d3fe898c9'}\n\n```{.r .cell-code}\nround(mean(bsa$leftrigh,na.rm=T),2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2.52\n```\n:::\n:::\n\n\n\nwould produce the same results using just one line of code .\n\n## Bivariate association between continuous variables\nR provides a wide range of bivariate statistics under its base packages. The cor() and  cov() functions provide basic measures of association between two variables. For instance, in order to measure the correlation between the leftright scale and the libertarian-authoritarian scale: The later variable is a numeric variable that details how far someone sits on the libartrian – authoritarian scale from 1 to 5\n\n\n\n\n::: {.cell hash='main_body_cache/pdf/5.9_31c3360955fbb0d4175fdce0491d8088'}\n\n```{.r .cell-code}\ncor(bsa$leftrigh, bsa$libauth, use='complete.obs')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.009625928\n```\n:::\n:::\n\n\n\n\nA correlation of 0.009 indicates an positive but very small relationship. It can be translated to mean ‘an increase in authoritarianism is associated with a marginal increase  in rightwing views.\n\nNote: When using the cor() and cov() functions  missing values are dealt with the ‘use=’ \"everything\", \"all.obs\", \"complete.obs\", \"na.or.complete\", or \"pairwise.complete.obs\" options. See ‘?cor’  for additional information.\n\n\n\n## Categorical Variables\nAs with continuous variables, R offers several tools that can be used to describe the distribution of  categorical variables. One- and two-way contingency tables are the most commonly used.\n\n### One way frequency tables\nThere are several R commands that we can use to create frequency tables. The most common ones   `table()`,`xtabs()` or `ftable()` which return the frequencies of observations within each level of a factor. For example, in order to obtain the political affiliation of BSA respondents in 2017:\n\n\n\n::: {.cell hash='main_body_cache/pdf/5.10_51eecf86f3d613b3161c77802514bbb0'}\n\n```{.r .cell-code}\ntable(bsa$PartyId2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n    Conservative           Labour Liberal Democrat      Other party \n            1263             1479              241              193 \n            None      Green Party \n             515               79 \n```\n:::\n:::\n\n\n\n\nAs with any other R functions, the outcome of `table()` can be stored as an object for further processing:\n\n\n\n::: {.cell hash='main_body_cache/pdf/5.11_6309b0cbcf67e117fd9f226e173f4546'}\n\n```{.r .cell-code}\na<-table(bsa$PartyId2)\n```\n:::\n\n\n\n\n\n`table()`  does not compute proportions or percentages. Proportions are obtained using the `prop.table()` function which in turn does not produce percentages. It is also a good idea to round the results for greater readability.\nEither:\n  \n\n\n\n::: {.cell hash='main_body_cache/pdf/5.12_a9b9a236cf0d63520e10b18ca04bbf19'}\n\n```{.r .cell-code}\nround(100*prop.table(a),1) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n    Conservative           Labour Liberal Democrat      Other party \n            33.5             39.2              6.4              5.1 \n            None      Green Party \n            13.7              2.1 \n```\n:::\n:::\n\n\n\n... or:\n  \n\n\n\n::: {.cell hash='main_body_cache/pdf/5.13_0887d40d15e772de55d99c17f0526514'}\n\n```{.r .cell-code}\nround(100*\n        prop.table(\n          table(bsa$PartyId2)\n        ),\n      1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n    Conservative           Labour Liberal Democrat      Other party \n            33.5             39.2              6.4              5.1 \n            None      Green Party \n            13.7              2.1 \n```\n:::\n:::\n\n\n\n\n### Two way or more contingency table\n\nThe simplest way to produce a two-way contingency table is to pass another variable to `table()`:\n  \n\n\n\n::: {.cell hash='main_body_cache/pdf/5.14_f568f50e04d15838601071bfb088c23a'}\n\n```{.r .cell-code}\ntable(bsa$PartyId2, bsa$Rsex)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                  \n                   Male Female\n  Conservative      627    636\n  Labour            644    835\n  Liberal Democrat  124    117\n  Other party        97     96\n  None              199    316\n  Green Party        31     48\n```\n:::\n:::\n\n\n\n\nHowever, when dealing with more than one variable it is recommended to use xtabs() instead as it has a number of desirable functions directly available as option. The syntax is slightly different as it relies on a formula ie a R object consisting of elements separated by a tilde '~'. The variables to be tabulated are specified on the right hand side of the formula.\n\n\n\n\n::: {.cell hash='main_body_cache/pdf/5.15_0e8b83d973184c7f699693c95faaee28'}\n\n```{.r .cell-code}\nxtabs(~PartyId2 +Rsex,\n      data = bsa)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                  Rsex\nPartyId2           Male Female\n  Conservative      627    636\n  Labour            644    835\n  Liberal Democrat  124    117\n  Other party        97     96\n  None              199    316\n  Green Party        31     48\n```\n:::\n:::\n\n\n\nThe `data=` parameter does not have to be explicitly specified as simply using ´`bsa`' will work. Other useful options are:\n\n- subset=, which allows direct specification of a subpopulation from which to derive the table;\n- drop.unused.levels=T to remove empty levels (categories with zero observations) from being displayed;\n- weights~ variables on the right hand side of the formula will be treated as weights, a useful feature for survey analysis. \n\nAs previously `prop.table()` is necessary in order to obtain proportions:\n\n\n\n\n::: {.cell hash='main_body_cache/pdf/5.16_11d4bcd02fe2442eb1c0e7e7c6a65524'}\n\n```{.r .cell-code}\nb<-xtabs(~PartyId2 +Rsex,bsa)\nround(100*prop.table(b),1) ### Cell percentages\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                  Rsex\nPartyId2           Male Female\n  Conservative     16.6   16.9\n  Labour           17.1   22.1\n  Liberal Democrat  3.3    3.1\n  Other party       2.6    2.5\n  None              5.3    8.4\n  Green Party       0.8    1.3\n```\n:::\n:::\n\n\n\nThe largest group in the sample (22.1%) is made of labour-voting females, the smallest of green-voting males.\n\n\n\n::: {.cell hash='main_body_cache/pdf/5.17_51b3f2b5aa0b72d656b73c1ac743f894'}\n\n```{.r .cell-code}\nround(100*prop.table(b,1),1) ### Option 1 for row percentages\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                  Rsex\nPartyId2           Male Female\n  Conservative     49.6   50.4\n  Labour           43.5   56.5\n  Liberal Democrat 51.5   48.5\n  Other party      50.3   49.7\n  None             38.6   61.4\n  Green Party      39.2   60.8\n```\n:::\n:::\n\n\n\nConservative voters are more or less evenly split between men and women, whereas Labour and Green voters are more likely to be women.\n\n\n\n::: {.cell hash='main_body_cache/pdf/5.18_a3cddc7624ba986472336647a0e8d09a'}\n\n```{.r .cell-code}\nround(100*prop.table(b,2),1) ### Option 2 for column percentages\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                  Rsex\nPartyId2           Male Female\n  Conservative     36.4   31.1\n  Labour           37.4   40.8\n  Liberal Democrat  7.2    5.7\n  Other party       5.6    4.7\n  None             11.6   15.4\n  Green Party       1.8    2.3\n```\n:::\n:::\n\n\n\nSimilar proportions of men voted Conservative and Labour (36-37%), whereas women were clearly more likely to vote Labour.\n\nFor some reason, there is not a straightforward way to obtain percentages in three-way contingency tables with either `xtabs()` or `table()`. This is where `ftable()` comes handy.\n\n\n\n::: {.cell hash='main_body_cache/pdf/5.19_bb51671a3337cc44a8f8c9584735f5df'}\n\n```{.r .cell-code}\nround(100*prop.table(\n  ftable(RAgeCat~PartyId2 +Rsex,data=bsa)\n  ,1),1) ### Option 2 for column percentages\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                        RAgeCat 18-24 25-34 35-44 45-54 55-59 60-64  65+\nPartyId2         Rsex                                                   \nConservative     Male             3.0   7.8  13.9  15.0   8.6   9.3 42.4\n                 Female           2.7   7.1   8.8  18.6   8.8   8.7 45.4\nLabour           Male             7.6  16.1  14.3  21.3   7.5   9.3 23.9\n                 Female           7.9  20.2  19.2  18.8   7.1   7.1 19.7\nLiberal Democrat Male             0.8  13.7  19.4  15.3   9.7   8.9 32.3\n                 Female           4.3   9.4  26.5   6.0   6.0   9.4 38.5\nOther party      Male             3.1  14.4  11.3  17.5  11.3  16.5 25.8\n                 Female           5.2  14.6  15.6  16.7  11.5   8.3 28.1\nNone             Male             7.5  22.1  20.6  17.1  11.1   6.0 15.6\n                 Female           8.5  22.5  20.6  21.8   7.3   6.3 13.0\nGreen Party      Male             6.5  32.3  16.1  29.0   6.5   3.2  6.5\n                 Female           6.2  18.8  25.0  20.8   6.2  10.4 12.5\n```\n:::\n:::\n\n\n\nThe tables gives the relative age breakdown for each gender/political affiliation combination (ie row percentages).\n\n\n## Grouped summary statistics for continuous variables\nA common requirement in survey analysis consist in being able to compare  descriptive statistics across subgroups of the data. There are different ways to do this in R. We demonstrate below the most straightforward  one, which is obtained by using some of the functions available in the `dplyr` package. \n\n\n\n\n::: {.cell hash='main_body_cache/pdf/5.20_04df755d77f09ffb64d8a4c56d40fa8e'}\n\n```{.r .cell-code}\nbsa%>%group_by(PartyId2)%>%summarise(\nmdscore=median(libauth,na.rm=T),\nsdscore=sd(libauth,na.rm=T))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 7 x 3\n  PartyId2         mdscore sdscore\n  <fct>              <dbl>   <dbl>\n1 Conservative        3.67   0.587\n2 Labour              3.33   0.774\n3 Liberal Democrat    3.17   0.726\n4 Other party         3.67   0.739\n5 None                3.67   0.584\n6 Green Party         2.83   0.872\n7 <NA>                3.67   0.564\n```\n:::\n:::\n\n\n\n\nThe above command produces a table of summary values (median and standard deviations) of the Liberal vs authoritarian scale. We can see from the first one that Green party voters are the most liberal, followed by Labour, whereas non voters and Conservatives are the most authoritarian. Liberal Democrats are the most cohesive group (ie with the smallest standard deviation).\n\n\n\n\n::: {.cell hash='main_body_cache/pdf/5.21_6a5bd46485d62cda14816f77fe70c990'}\n\n```{.r .cell-code}\nbsa%>%group_by(Rsex,PartyId2)%>%summarise(\nmnscore=sd(libauth,na.rm=T) ,mdscore=median(libauth,na.rm=T))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 14 x 4\n# Groups:   Rsex [2]\n   Rsex   PartyId2         mnscore mdscore\n   <fct>  <fct>              <dbl>   <dbl>\n 1 Male   Conservative       0.607    3.67\n 2 Male   Labour             0.765    3.33\n 3 Male   Liberal Democrat   0.766    3.17\n 4 Male   Other party        0.703    3.83\n 5 Male   None               0.616    3.67\n 6 Male   Green Party        1.04     2.67\n 7 Male   <NA>               0.603    3.67\n 8 Female Conservative       0.565    3.67\n 9 Female Labour             0.781    3.33\n10 Female Liberal Democrat   0.688    3.17\n11 Female Other party        0.773    3.67\n12 Female None               0.565    3.67\n13 Female Green Party        0.744    3   \n14 Female <NA>               0.540    3.67\n```\n:::\n:::\n\n\n\n\nWhen further broken down by gender, we can see that overall the same trends remain valid, with some nuances: male Green supporters are markedly more liberal than their female counterpart, the opposite being true among Conservative supporters. \n\nInstead of tables of summary statistics, we may want to have summary statistics computed as variables that will be added to the current dataset for each corresponding gender/political affiliation group. This is straightforward to do with dplyr, we just need to use the `mutate()` command.  \n\n\n\n\n::: {.cell hash='main_body_cache/pdf/5.22_f6bebd521854117d596c03dc767e7273'}\n\n```{.r .cell-code}\nbsa<-\nbsa%>%group_by(Rsex,PartyId2)%>%mutate(\nmsscore=sd(libauth,na.rm=T) ,mdscore=median(libauth,na.rm=T))\n```\n:::\n\n\n\nHowever, we also need to add the newly created variables into the existing bsa dataset, which the first line of the syntax above does. We can check that the variables have been created and that the correct values have been allocated to each sex/affiliation category.\n\n\n\n\n::: {.cell hash='main_body_cache/pdf/5.23_6b89ffba984423875e5623d5864c2001'}\n\n```{.r .cell-code}\nnames(bsa)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"Sserial\"          \"Rsex\"             \"RAgeCat\"          \"Married\"         \n [5] \"ChildHh\"          \"HEdQual3\"         \"eq_inc_quintiles\" \"RClassGp\"        \n [9] \"CCBELIEV\"         \"carallow\"         \"carreduc\"         \"carnod2\"         \n[13] \"cartaxhi\"         \"carenvdc\"         \"plnenvt\"          \"plnuppri\"        \n[17] \"Politics\"         \"Voted\"            \"actchar\"          \"actpol\"          \n[21] \"govnosa2\"         \"PartyId2\"         \"leftrigh\"         \"libauth\"         \n[25] \"WtFactor\"         \"lnleftrigh_log\"   \"govnosa2.n\"       \"lngovnosa2\"      \n[29] \"test\"             \"Married2\"         \"Married3\"         \"RAgeCat2\"        \n[33] \"msscore\"          \"mdscore\"         \n```\n:::\n\n```{.r .cell-code}\nbsa[4:8,c(\"Rsex\",\"PartyId2\",\"mdscore\")]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 x 3\n# Groups:   Rsex, PartyId2 [4]\n  Rsex   PartyId2         mdscore\n  <fct>  <fct>              <dbl>\n1 Female Labour              3.33\n2 Male   Liberal Democrat    3.17\n3 Female <NA>                3.67\n4 Male   Liberal Democrat    3.17\n5 Female Green Party         3   \n```\n:::\n:::\n\n\n\n\n\\newpage\n\n\n\n# Producing weighted estimates\n  \nMost users   of social surveys are interested at some point in inferring nationally representative estimates and/or compensate for bias involved in the sampling process when conducting analyses: sampling and non-response bias. These are often tackled with sampling weights, which are meant to correct estimates for the under/over representation of certain groups in the sample and adjusts standard errors accordingly. \n  \nHowever, robust inference usually relies not just on weighting estimates   but also on factoring in the survey design when conducting analyses -- which can be done with the `survey` package in R, but  is a topic that goes beyond the present guide. At the same time for users who are concerned with reducing bias rather than producing publication-quality estimates, it may be useful to be aware how common R commands and operations can be used with weights. \n  \nSome of the most common ones are mentioned below:\n    \n## Central tendency and dispersion (continuous variables)\n\nThe `stats` packages which comes with the  installation of Base R includes `weighted.mean()` which, as indicated by its name, computes weighted estimates of the mean of a variable when weights are provided. However the Hmisc package includes a more comprehensive set of functions that can be used when weighting estimates. The code below provides an illustration of weighted means, variance and median of the left-right score used before, each time comparing it with the unweighted estimate:\n    \n\n\n\n::: {.cell messages='false' hash='main_body_cache/pdf/6.1_f5be8d7ab9ee019328aae68be45ce094'}\n\n```{.r .cell-code}\n### Mean\n  c(mean(bsa$leftrigh,na.rm=T),wtd.mean(bsa$leftrigh,bsa$WtFactor))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2.520 2.522\n```\n:::\n\n```{.r .cell-code}\n### Variance\n  c(var(bsa$leftrigh,na.rm=T),wtd.var(bsa$leftrigh,bsa$WtFactor))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.6167 0.6195\n```\n:::\n\n```{.r .cell-code}\n### Median and quartiles\n  c(quantile(bsa$leftrigh,na.rm=T,probs=c(.25,.5,.75)),\n    wtd.quantile(bsa$leftrigh,bsa$WtFactor,probs=c(.25,.5,.75)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n25% 50% 75% 25% 50% 75% \n2.0 2.4 3.0 2.0 2.4 3.0 \n```\n:::\n:::\n\n\n\n  \n  The above functions can be used in conjunction with `group_by()` and `summarise()` in order  to compute weighted estimates of continuous variables by groups of categorical variables:\n    \n\n\n\n::: {.cell messages='false' hash='main_body_cache/pdf/6.2_03b28dfe976d104a383325fcecea2f4e'}\n\n```{.r .cell-code}\n  bsa%>%\n  filter(!is.na(RAgeCat))%>%group_by(RAgeCat)%>%\n  summarise(Mean=wtd.mean(leftrigh,WtFactor),\n            Var=wtd.var(leftrigh,WtFactor),\n            Median=wtd.quantile(leftrigh,WtFactor,probs=c(.5)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 7 x 4\n  RAgeCat  Mean   Var Median\n  <fct>   <dbl> <dbl>  <dbl>\n1 18-24    2.49 0.556    2.4\n2 25-34    2.56 0.577    2.6\n3 35-44    2.52 0.615    2.4\n4 45-54    2.53 0.671    2.6\n5 55-59    2.54 0.653    2.4\n6 60-64    2.46 0.685    2.4\n7 65+      2.52 0.613    2.4\n```\n:::\n:::\n\n\n\n  \n## Frequencies and contingency tables\n  \n  Neither `ftable()` or `table()` used above allow for using weights. And although the `Hmisc` packages includes the `wtd.table()` function for single frequency tables, we recommend using `xtabs()` as previously, as it it more versatile:\n    \n\n\n\n::: {.cell messages='false' hash='main_body_cache/pdf/6.3_86d19da6410062554ecbede8afed0961'}\n\n```{.r .cell-code}\n## Unweighted vs weighted frequency tables\n  cbind(Unweighted=round(100*prop.table(xtabs(~plnenvt,bsa)),1),\n        Weighted=round(100*prop.table(xtabs(WtFactor~plnenvt,bsa)),1)\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                           Unweighted Weighted\nagree strongly                    4.6      4.8\nagree                            16.0     15.9\nneither agree nor disagree       33.2     33.2\ndisagree                         36.3     37.0\ndisagree strongly                10.0      9.0\n```\n:::\n:::\n\n\n\n  \n  Weights are passed to `xtabs()` by specifying their name on the left hand side of the equation (or the tilde `~` ) \n  \n  Obtaining weighted contingency tables follow the same logic:\n\n\n\n::: {.cell messages='false' hash='main_body_cache/pdf/6.4_73fa71b22f0a8ac2082ae80ca3fc03a6'}\n\n```{.r .cell-code}\n## Unweighted vs weighted contingency tables\n  cbind(round(100*prop.table(xtabs(~plnenvt+Rsex,bsa),1),1),\n        round(100*prop.table(xtabs(WtFactor~plnenvt+Rsex,bsa),1),1)\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                           Male Female Male Female\nagree strongly             50.0   50.0 46.1   53.9\nagree                      47.2   52.8 53.5   46.5\nneither agree nor disagree 40.8   59.2 43.6   56.4\ndisagree                   47.9   52.1 52.7   47.3\ndisagree strongly          42.3   57.7 41.5   58.5\n```\n:::\n:::\n\n\n\n  \n## Robust inference\n  \n  The weighting procedures described above could be described as 'quick and dirty' in that they mostly compute point estimates -- ie a single value -- and do not provide  a reliable idea of their precision. Computing the precision of survey data estimates -- usually via their standard error -- usually requires more than just adding weights to a command. Information about the survey design, its primary sampling units, strata and clusters is requires so that robust standard errors, statistical tests and/or confidence interval are computed.\n  \n  The `Survey` package was designed in order to deal with this set of issues. It provides functions for integrating survey design into R as well as computing common estimates. We describe below the most important features. In order to  use survey fonctions consist one first needs to create a svydesign object, in essence a version of the data that incorporates the sample design information available, then to compute the estimate using the svydesign object.\n  \n  An common issue with survey datasets available in the UK is that  sampling information is often only available in secure lab version of the data, restricting its access to authorised users. Although it is sometimes possible to use  available variables to account for aspects of the sample design -- region as a strata in the case of stratified samples -- in most cases users are left with computing standard errors without sample design information, which amounts to assuming that the sample was drawn purely at random. Even if this is the case however, using  the `survey` package is recommended, as it provides a coherent framework for computing survey parameters.     \n  \n  \n\n\n\n::: {.cell messages='false' hash='main_body_cache/pdf/6.5_ad9c93e9b15d7e2b42a037938aa62ed7'}\n\n```{.r .cell-code}\n  library(survey) ### Loading the package in memory\n  bsa.design<-svydesign(ids =~1,weights=~WtFactor,data=bsa) \n```\n:::\n\n\n\n  \n  The code above simply declares the survey design by creating the `bsa.design` object (the name is arbitrary). The `ids=` parameter is where  primary sampling units are declared, as well as any clustering information as a formula ie `~PSU+cluster2id...`. When PSU information is unavailable `ids` is given the value 1 or 0. A `strata=` and `fpc=` are available in order to declare the sampling strata and the variable used for finite population correction. None of these are available in the bsa dataset, and estimation commands will therefore rely on the assumption of simple random sampling.\n  \n  We can now compute estimates similar estimates as in the previous sections. The code below provides the mean of the left vs right political orientation indicator, as well as its 95% confidence interval: \n    \n\n\n\n::: {.cell messages='false' hash='main_body_cache/pdf/6.6_7c2b6c70a821b602a222a1c1a5bb48c0'}\n\n```{.r .cell-code}\n  svymean(~leftrigh,bsa.design,na.rm = T)### Computes the mean and its standard error...\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         mean   SE\nleftrigh 2.52 0.02\n```\n:::\n\n```{.r .cell-code}\n  confint(svymean(~leftrigh,bsa.design,na.rm = T)) ### ... and confidence interval\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         2.5 % 97.5 %\nleftrigh 2.491  2.552\n```\n:::\n:::\n\n\n\n  And now for the median:\n\n\n\n\n::: {.cell messages='false' hash='main_body_cache/pdf/6.7_fc52b6722947df6b1802e01c63324413'}\n\n```{.r .cell-code}\n  svyquantile(~leftrigh,bsa.design,quantiles=.5,na.rm = T)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$leftrigh\n    quantile ci.2.5 ci.97.5    se\n0.5      2.4    2.4     2.6 0.051\n\nattr(,\"hasci\")\n[1] TRUE\nattr(,\"class\")\n[1] \"newsvyquantile\"\n```\n:::\n:::\n\n\n\n\n  Frequency and contingency tables are computed using `svytable()`, which follows the same syntax as `xtabs()`\n\n\n\n\n::: {.cell messages='false' hash='main_body_cache/pdf/6.8_2cd52b9fd2cb266501251eddd0f89e06'}\n\n```{.r .cell-code}\n### A frequency table...\n  round(100*\n          prop.table(\n            svytable(~RAgeCat,bsa.design)\n          ),1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRAgeCat\n18-24 25-34 35-44 45-54 55-59 60-64   65+ \n 11.2  17.2  16.1  17.9   7.9   6.8  22.8 \n```\n:::\n\n```{.r .cell-code}\n### And a two-way contingency table:\n  \n  round(100*\n          prop.table(\n            svytable(~RAgeCat+Rsex,bsa.design)\n            ,1),1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       Rsex\nRAgeCat Male Female\n  18-24 51.1   48.9\n  25-34 50.2   49.8\n  35-44 49.7   50.3\n  45-54 49.3   50.7\n  55-59 48.8   51.2\n  60-64 49.0   51.0\n  65+   45.4   54.6\n```\n:::\n:::\n\n\n\n  \n  \n# Graphs and plots\n  There are two main ways to produce graphs in R: either by using the straightforward but rather basic plotting commands from the Base package, or the more complex and nicer looking functions from the `ggplot` package. \n  \n## Distributional graphs for continuous variables\n  Graphs such as histograms or box plots are a convenient way to gain a quick overview of the distribution of a variable and are easy  to produce. Go back to the BSA data, we can plot the distribution of left-right political orientations scores with the `hist()` command. \n  \n\n\n\n::: {.cell hash='main_body_cache/pdf/7.1_218813463755d6a6eaab4bda2ce54ce9'}\n\n```{.r .cell-code}\n  hist(bsa$leftrigh,freq=FALSE)\n```\n\n::: {.cell-output-display}\n![](main_body_files/figure-pdf/7.1-1.pdf){fig-pos='H' fig-alt='Unformatted histogram of left-right political orientations scores'}\n:::\n:::\n\n\n\n  \n  The graphs appear  visible in the ‘Plot’ tab on the right hand side of the R Studio window. It shows us that political orientations are slightly skewed towards the left. The `freq=FALSE` option requires the y-axis to be expressed in terms of proportions rather than frequencies.\n  \n  Titles and labels can easily be added:\n    \n\n\n\n::: {.cell hash='main_body_cache/pdf/7.2_1367faac774dfe0b292737b7c1f37a5a'}\n\n```{.r .cell-code}\n  hist(bsa$leftrigh,\n       freq=FALSE,\n       main=\"Histogram of political orientations\",\n       ylab=\"Proportions\",\n       xlab=\"Left-right political orientations score\")\n```\n\n::: {.cell-output-display}\n![](main_body_files/figure-pdf/7.2-1.pdf){fig-pos='H' fig-alt='Histogram of left vs right political orientations, with title and y axis labels'}\n:::\n:::\n\n\n\n  \n  Note that `main`, `ylab` and `xlab` can be used with any Base R plot commands. \n  \n  We can also produce a box and whisker plot of the same variable:\n\n\n\n::: {.cell hash='main_body_cache/pdf/7.3_4903fab8b95b99c935da39f21c0fe34c'}\n\n```{.r .cell-code}\n  boxplot(bsa$leftrigh,\n          main=\"Box and whisker plot of political orientations\",\n          ylab=\"Left-right political orientations score\"\n  )\n```\n\n::: {.cell-output-display}\n![](main_body_files/figure-pdf/7.3-1.pdf){fig-pos='H' fig-alt='Box and whisker plot of left vs right political orientations, with title and y axis labels'}\n:::\n:::\n\n\n\n  \n  The generic `plot()` command produces one or two-way scatterplots:\n    \n\n\n\n::: {.cell hash='main_body_cache/pdf/7.4.1_bcf559e925efaa879cae4f92d8f31469'}\n\n```{.r .cell-code}\n  plot(bsa$leftrigh) ### One way scatter plot of left-right political orientations score\n```\n\n::: {.cell-output-display}\n![](main_body_files/figure-pdf/7.4.1-1.pdf){fig-pos='H' fig-alt='Raw scatterplot of left-right political orientations'}\n:::\n:::\n\n::: {.cell hash='main_body_cache/pdf/7.4.2_85a24dc2c0fbd316e4a0a496ffc89f49'}\n\n```{.r .cell-code}\n  plot(bsa$leftrigh,bsa$libauth) \n```\n\n::: {.cell-output-display}\n![](main_body_files/figure-pdf/7.4.2-1.pdf){fig-pos='H' fig-alt='Raw scatterplot of left-right political orientations vs authoritarianism score'}\n:::\n:::\n\n\n\n                  \n  The second graph shows us that there is little association between the two variables. However,  slightly fewer respondents simultaneously score  high on the authoritarianism and left vs right scales.  \n  \n## Plotting categorical variables\n  \nThe generic `plot()` function provides a quick way to produce bar plots of categorical data. For example, we can examine the distribution of political party affiliations (`Politics` variable) which is a factor (ie categorical) variable. Some preliminary abbreviating of the factor levels are required in order for them to be displayed properly. \n  \n\n\n\n::: {.cell hash='main_body_cache/pdf/7.5_13b94fd713269984a1f7f511567a8183'}\n\n```{.r .cell-code}\n  levels(bsa$PartyId2) ## The third and fourth factor levels are a bit long\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Conservative\"     \"Labour\"          \n[3] \"Liberal Democrat\" \"Other party\"     \n[5] \"None\"             \"Green Party\"     \n```\n:::\n\n```{.r .cell-code}\n  levels(bsa$PartyId2)<-c(\"Con\",\"Lab\",\"Lib Dems\",\"Other\",\"None\", \"Greens\") \n  plot(bsa$PartyId2)\n```\n\n::: {.cell-output-display}\n![](main_body_files/figure-pdf/7.5-1.pdf){fig-pos='H' fig-alt='Default frequency bar plot of political party affiliation using the plot command'}\n:::\n:::\n\n\n\n\nMore advanced plots require the barplot() function, which can be used in conjunction with table(). Whereas table() creates the data that will be plotted, barplot() does the actual plotting. For instance, we can produce the same bar plot, but this time with percentages, by creating a frequency table as we did above in Section 5.2, then plot it.\n  \n\n\n\n::: {.cell hash='main_body_cache/pdf/7.6_9a5d1b567b22e622cf0ef049e4bed051'}\n\n```{.r .cell-code}\n  party.tab<-round(100*prop.table(\n    table(bsa$PartyId2)\n  ),\n  1)\n  \n  party.tab\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n     Con      Lab Lib Dems    Other     None   Greens \n    33.5     39.2      6.4      5.1     13.7      2.1 \n```\n:::\n\n```{.r .cell-code}\n  barplot(party.tab,\n          main=\"Political party affiliation\",\n          ylab=\"Percent\")\n```\n\n::: {.cell-output-display}\n![](main_body_files/figure-pdf/7.6-1.pdf){fig-pos='H' fig-alt='Neater frequency bar plot of political party affiliation using the barplot command'}\n:::\n:::\n\n\n\n  \n  We can go further and create plots for two-way contingency tables of party affiliation by gender. This time we will do it in a single command:\n    \n\n\n\n::: {.cell hash='main_body_cache/pdf/7.7_e83e9c0b02535ae8a35c59147335e9c5'}\n\n```{.r .cell-code}\n  barplot(\n    round(100*prop.table(\n      table(bsa$Rsex,bsa$PartyId2),\n      2),              ## Column % (here, gender)\n      1),               ## Rounded to 1 decimal\n    beside = T,     ## Side-by-side bars   \n    main=\"Political party affiliation by gender\",\n    ylab=\"Percent\")\n```\n\n::: {.cell-output-display}\n![](main_body_files/figure-pdf/7.7-1.pdf){fig-pos='H' fig-alt='Two-way frequency bar plot of political party affiliation by gender using the barplot command'}\n:::\n:::\n\n\n\n  \n## More advanced plots\n  Social science research often requires more advanced plots in order to conduct more complex analyses, for instance comparing the mean or median value of a continuous outcome across two or more categorical variables. The `ggplot` package  provides one of the most advanced set of tools for plotting data  currently available. A few examples are provided below.\n  \n  \n  ***Political party affiliation by highest qualification and gender***\n    We would like to look at how differences in political party affiliations vary by gender and whether respondents have a degree-level education.\n  \n  Let us first prepare the data: we need to create the table of result, the proportion of degree vs non degree holders by gender and political party. This is a three-way contingency table, that we can obtain with `ftable()` as shown in Section 5.2, combined with `prop.table()` for the computation of proportions and `round()`.\n  As they are more straightforward to handle in `ggplot`, we convert the table object created by ftable into a data frame. Although we can specify titles and axis labels  in the plotting command, it is preferable  to keep things simple here and have them already in the the data.   \n  Rather than using the full range of educational achievements recorded in `HEdQual3`, we would like instead to have a dichotomic variable between degree holders and non degree holders. Adding it directly in the ftable command as a boolean expression return a dichotomic variable: \"TRUE\" for Degree educated respondents, and \"FALSE\" for everyone else. We just need to change the levels of this factor variable to make them more intelligible. Finally we change the variable names in our data frame. \n  \n\n\n\n::: {.cell hash='main_body_cache/pdf/7.8_ac6c07cd40e990e302672bc9bf36ca81'}\n\n```{.r .cell-code}\n  pa<-round(100*prop.table((ftable(bsa$PartyId2,bsa$Rsex,(bsa$HEdQual3==\"Degree\"))),1),1)\n  pa<-data.frame(pa)\n  levels(pa$Var3)<-c(\"Below\",\"Degree\")\n  names(pa)<-c(\"Affiliation\",\"Gender\",\"Education\",\"Percent\")\n  pa\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Affiliation Gender Education Percent\n1          Con   Male     Below    72.7\n2          Lab   Male     Below    70.1\n3     Lib Dems   Male     Below    50.0\n4        Other   Male     Below    86.5\n5         None   Male     Below    88.8\n6       Greens   Male     Below    43.3\n7          Con Female     Below    82.6\n8          Lab Female     Below    67.3\n9     Lib Dems Female     Below    54.4\n10       Other Female     Below    74.7\n11        None Female     Below    83.9\n12      Greens Female     Below    48.9\n13         Con   Male    Degree    27.3\n14         Lab   Male    Degree    29.9\n15    Lib Dems   Male    Degree    50.0\n16       Other   Male    Degree    13.5\n17        None   Male    Degree    11.2\n18      Greens   Male    Degree    56.7\n19         Con Female    Degree    17.4\n20         Lab Female    Degree    32.7\n21    Lib Dems Female    Degree    45.6\n22       Other Female    Degree    25.3\n23        None Female    Degree    16.1\n24      Greens Female    Degree    51.1\n```\n:::\n:::\n\n\n\n  We are now ready to plot the data.  the `ggplot()` commands usually works as a succession of layers or  options that are added to an initial plot specifications. Each extra layer is added after a `+` sign. In the example below, we specify the data and the aesthetic (ie the main parameters of the plot) with the first command: the x and y variables , and the first grouping variable, education). `geom_bar()` stipulates the bar plot, with the ṕosition=\"dodge\" for the bars to be located side by side (position=\"stack\"would have them on top of each other). Finally, facet_wrap() splits the plot by gender.\n\n\n\n::: {.cell hash='main_body_cache/pdf/7.9_3ff4a15d341f35d3db2ebf9f484c82ce'}\n\n```{.r .cell-code}\n    ggplot(data=pa,aes(y=Percent,x=Affiliation,fill=Education))+\n    geom_bar(position=\"dodge\",stat=\"identity\")+\n    facet_wrap(~Gender)+\n    theme_minimal()+                  ### Theme for visualisation\n    scale_fill_manual(values=c(\"#702082\", \"#008755\"))+ ### Custom colours (optional)\n    theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](main_body_files/figure-pdf/7.9-1.pdf){fig-pos='H' fig-alt='Bar plot of political party affiliation by gender and qualification using ggplot'}\n:::\n:::\n\n\n\n\n  \\newpage\n  \n  \n# Statistical testing\n  This section covers how to implement common statistical tests in R with survey data. A working knowledge of these tests and their theoretical assumptions is assumed.\n  \n## Differences between means\n  \n  Two common ways of conducting statistical testing with means in samples consist in testing  whether they are significantly different from 0 (one  sample t-test), or whether they differ between two  groups (two samples t test). In the latter case, one can further distinguish between independent samples (where means come from different groups), or paired  samples (when the same measure is taken at several point in time). Given that it is the most widely used in social science, we will only cover the former here.\n  \n  Several R packages provide functions for conducting t tests. We will be using `t.test()`, part the `stats` package. Suppose we would like to test whether `libauth` significantly differs between men and women. A two sided test is the default (with H_0 that there is no differences between groups), and H_1 that the  group means do indeed differ. The test is specified with a formula with on the left hand side the quantity to be tested and on the right  hand side the grouping variable. \n  \n  One sided tests can be conducted by specifying that the alternative hypothesis (H_1) is either **greater** or **less**. `t.test()` assumes that by default the variances are unequal. this can be changed with the `var.equal=T` option.\n  \n\n\n\n::: {.cell hash='main_body_cache/pdf/8.1_9174cd54d482e8823073464d8f02b0bb'}\n\n```{.r .cell-code}\n# Testing for significant differences in liberal vs authoritarian score\n  t.test(libauth~Rsex,data=bsa)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWelch Two Sample t-test\n\ndata:  libauth by Rsex\nt = 1.2, df = 3012, p-value = 0.2\nalternative hypothesis: true difference in means between group Male and group Female is not equal to 0\n95 percent confidence interval:\n -0.02035  0.07959\nsample estimates:\n  mean in group Male mean in group Female \n               3.528                3.498 \n```\n:::\n:::\n\n\n\n  No significant differences (ie the difference in  `libauth` between men and women is not significantly different from zero)\n\n\n\n::: {.cell hash='main_body_cache/pdf/8.2_77b0cc426a5630593c78b2c85aa934c5'}\n\n```{.r .cell-code}\n# Testing for whether men have a lower (ie more left-wing)  score\n  t.test(leftrigh~Rsex,data=bsa, alternative=\"less\")      \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWelch Two Sample t-test\n\ndata:  leftrigh by Rsex\nt = -2.1, df = 2858, p-value = 0.02\nalternative hypothesis: true difference in means between group Male and group Female is less than 0\n95 percent confidence interval:\n     -Inf -0.01198\nsample estimates:\n  mean in group Male mean in group Female \n               2.488                2.546 \n```\n:::\n:::\n\n\n\n  Men have a significantly lower  score on the scale (at the .05 threshold)  and are therefore on average leaning more to the left than women.\n  \n  \n## Differences in variance\n  \n  Another common significance test in social science is the **variance test** which consists of  testing whether the variances of the same variable across two groups  are equal. This is usually achieved by testing whether the ratio of the variance between the two groups is significantly different from zero. With the BSA data, this amounts to testing whether men and women are more homogenous with regard to their political views.\n  \n  The syntax for the variance test `var.test()` also included in `stats` is almost identical to that of `t.test()`\n  \n\n\n\n::: {.cell hash='main_body_cache/pdf/8.3_993fd46219440bfa7ab281ba88e56036'}\n\n```{.r .cell-code}\n# Testing for gender differences in liberal vs authoritarian score\n  var.test(libauth~Rsex,data=bsa)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tF test to compare two variances\n\ndata:  libauth by Rsex\nF = 1.1, num df = 1434, denom df = 1777, p-value\n= 0.09\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.9874 1.2022\nsample estimates:\nratio of variances \n             1.089 \n```\n:::\n:::\n\n\n\n  Significant differences in the variance  between men and women, but only at the .1 threshold.\n\n\n\n::: {.cell hash='main_body_cache/pdf/8.4_7d50b8146f1ae3cf03dc2afa45e9e4f6'}\n\n```{.r .cell-code}\n# Testing for whether men have a lower (ie more left-wing)  score\n  var.test(leftrigh~Rsex,data=bsa,alternative=\"greater\")      \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tF test to compare two variances\n\ndata:  leftrigh by Rsex\nF = 1.3, num df = 1433, denom df = 1771, p-value\n= 1e-08\nalternative hypothesis: true ratio of variances is greater than 1\n95 percent confidence interval:\n 1.217   Inf\nsample estimates:\nratio of variances \n             1.322 \n```\n:::\n:::\n\n\n\n  The variance of left-right political leaning is larger among men than women, in other words there are more divergence between men than between women.\n  \n## Significance of measures of association\n  \n**Between continuous variables**\n    \nAnother type of  common statistical   test in social science is about examining whether a coefficient of correlation is significantly different from 0 (alternative hypothesis).\n  \n\n\n\n::: {.cell hash='main_body_cache/pdf/8.5_4f40cd280aa72af022ac89737c4ea955'}\n\n```{.r .cell-code}\n  cor.test(bsa$leftrigh, bsa$libauth, use='complete.obs')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPearson's product-moment correlation\n\ndata:  bsa$leftrigh and bsa$libauth\nt = 0.54, df = 3202, p-value = 0.6\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.02501  0.04424\nsample estimates:\n     cor \n0.009626 \n```\n:::\n:::\n\n\n\n  \nAs we could have suspected the coefficient of correlation between the two scales is so small that it cannot be said to be  significantly  different from zero.\n  \n  **Between categorical variables**\n    \nThe chi-square test of independence is a very common  test of association between categorical variables. It consists in examining whether the association between two variables is likely to be due to chance or not, in other words whether the variability observed in a contingency table is significantly different from what would be expected were it due to chance.\n  \n  We will be using `chisq.test()`, also  from the `stats` package. By contrast with the test of correlation, the `chisq.test()` needs to be applied to  contingency tables that have already been computed.\n  Let us go back to an earlier example, and attempt to test whether the gender differences in political affiliations are due to chance or not. \n  \n\n\n\n::: {.cell hash='main_body_cache/pdf/8.6_6fb5f2796fdabf2ff8b4db9e0e9ae89d'}\n\n```{.r .cell-code}\n  chisq.test(xtabs(~PartyId2 +Rsex,bsa))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPearson's Chi-squared test\n\ndata:  xtabs(~PartyId2 + Rsex, bsa)\nX-squared = 27, df = 5, p-value = 5e-05\n```\n:::\n:::\n\n\n\n  \n  As the R output shows, there are highly significant gender differences in political affiliations (p<.001).\n  \n  \\newpage\n  \n  \n  \n# Regression analysis\n  The `glm()` command from the R base package is  used for fitting linear and non-linear models. These include logistic regression, and more generally models falling under the Generalized Linear Model framework.  \n  In this section, we will use it to investigate the association between the level of education `HEdQual3` and `Voted`, whether someone voted or not. Let’s first briefly explore the variables using the `class()` and `table()` commands from the previous chapters:\n    \n\n\n\n::: {.cell hash='main_body_cache/pdf/9.1_40d7f93a719288268a26b242c6ee9428'}\n\n```{.r .cell-code}\n  class(bsa$Voted)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"factor\"\n```\n:::\n\n```{.r .cell-code}\n  table(bsa$Voted)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n Yes   No \n2205  776 \n```\n:::\n:::\n\n\n\n  and \n  \n\n\n\n::: {.cell hash='main_body_cache/pdf/9.2_a703817559ad5cb8c0f3c54c89cc4f1e'}\n\n```{.r .cell-code}\n  class(bsa$HEdQual3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"factor\"\n```\n:::\n\n```{.r .cell-code}\n  table(bsa$HEdQual3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n                          Degree \n                            1050 \nHigher educ below degree/A level \n                            1086 \n            O level or equiv/CSE \n                            1026 \n                No qualification \n                             747 \n```\n:::\n:::\n\n\n\n  \n  It is a good idea to make sure that  categorical variables are stored as factors. This is not absolutely necessary, but gives greater flexibility, for instance when having to change the reference category on the go.\n  \n  For greater readability we can also shorten the levels of `HEdQual3`  using the `level()` function:\n    \n\n\n\n::: {.cell hash='main_body_cache/pdf/9.3_60ed21872f4d2ed5d0543fd7cca82c51'}\n\n```{.r .cell-code}\n  levels(bsa$HEdQual3) ### The original level names  are a bit verbose...\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Degree\"                          \n[2] \"Higher educ below degree/A level\"\n[3] \"O level or equiv/CSE\"            \n[4] \"No qualification\"                \n```\n:::\n\n```{.r .cell-code}\n### ... Fortunately we can shorten them easily\n  levels(bsa$HEdQual3) <- c(\"Degree\",\"A level and above\",\"GCSE or equiv\",\"No Qual\")\n  \n  table(bsa$HEdQual3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n           Degree A level and above     GCSE or equiv \n             1050              1086              1026 \n          No Qual \n              747 \n```\n:::\n:::\n\n\n\n  \n  What about the levels for our dependent variable? By default, the first level of a factor will be used as the reference category. This can be also checked with the `contrasts()`. In this case,  1 is associated with ‘No’, so the model will be predicting the probability of NOT voting. If the 1 was associated with ‘Yes’ then the model will be predicting the probability of voting.\n  \n\n\n\n::: {.cell hash='main_body_cache/pdf/9.4_c0ddf6c659691560321eee89eca3020b'}\n\n```{.r .cell-code}\n  levels(bsa$Voted) #Note that Yes comes before No\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Yes\" \"No\" \n```\n:::\n\n```{.r .cell-code}\n  contrasts(bsa$Voted)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    No\nYes  0\nNo   1\n```\n:::\n:::\n\n\n\n  \n  As we are interested in the latter we need to change the reference category using the `relevel()` function. We can also create a new variable named `Voted2` so as to keep a copy of the original variable intact. \n  \n\n\n\n::: {.cell hash='main_body_cache/pdf/9.5_db02c6619c7178e4046fc1259957a3cd'}\n\n```{.r .cell-code}\n# Reverse the order\n  bsa$Voted2 <- relevel(bsa$Voted, ref = \"No\")\n  \n#Check the contrasts\n  contrasts(bsa$Voted2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    Yes\nNo    0\nYes   1\n```\n:::\n:::\n\n\n\n  Since the outcome  variable (Voted or Voted2) has a binomial distribution, we need to specify to the glm() function that we will be fitting a logistic regression model. We will do this by setting the argument 'family'  to 'binomial' and the link function to 'logit'. We could  also have used 'probit' instead as a link function.\n  The code below runs the model and stores the result into an object called `fit1`:\n    \n    \n\n\n\n::: {.cell hash='main_body_cache/pdf/9.6_847f35ca93c2488058a499f887fa2a7c'}\n\n```{.r .cell-code}\n  fit1 <- glm(Voted2 ~ HEdQual3, data=bsa, family=binomial(link=logit))\n  summary(fit1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = Voted2 ~ HEdQual3, family = binomial(link = logit), \n    data = bsa)\n\nCoefficients:\n                          Estimate Std. Error z value\n(Intercept)                 1.4956     0.0919   16.28\nHEdQual3A level and above  -0.2134     0.1251   -1.71\nHEdQual3GCSE or equiv      -0.6406     0.1219   -5.25\nHEdQual3No Qual            -0.8367     0.1277   -6.55\n                          Pr(>|z|)    \n(Intercept)                < 2e-16 ***\nHEdQual3A level and above    0.088 .  \nHEdQual3GCSE or equiv      1.5e-07 ***\nHEdQual3No Qual            5.6e-11 ***\n---\nSignif. codes:  \n0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 3297.6  on 2916  degrees of freedom\nResidual deviance: 3240.4  on 2913  degrees of freedom\n  (1071 observations deleted due to missingness)\nAIC: 3248\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n:::\n\n\n\n  \n  To run a model  controlling for gender ‘Rsex’ and age ‘RAgeCat’, one  simply needs to add them on the right hand side of the formula, separated with a plus (+) sign. \n  \n\n\n\n::: {.cell hash='main_body_cache/pdf/9.7_e42db540cc64c033fbc99a62dd6444a0'}\n\n```{.r .cell-code}\n  fit2 <- glm(Voted2 ~ HEdQual3 + Rsex + RAgeCat, data=bsa, family=binomial(link=logit))\n  summary(fit2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = Voted2 ~ HEdQual3 + Rsex + RAgeCat, family = binomial(link = logit), \n    data = bsa)\n\nCoefficients:\n                          Estimate Std. Error z value\n(Intercept)                 1.1125     0.2004    5.55\nHEdQual3A level and above  -0.3868     0.1322   -2.93\nHEdQual3GCSE or equiv      -0.9902     0.1311   -7.55\nHEdQual3No Qual            -1.9063     0.1569  -12.15\nRsexFemale                 -0.1571     0.0922   -1.70\nRAgeCat25-34               -0.2460     0.1967   -1.25\nRAgeCat35-44                0.2067     0.1981    1.04\nRAgeCat45-54                0.8569     0.2000    4.28\nRAgeCat55-59                0.8406     0.2323    3.62\nRAgeCat60-64                1.6028     0.2527    6.34\nRAgeCat65+                  2.1641     0.2145   10.09\n                          Pr(>|z|)    \n(Intercept)                2.9e-08 ***\nHEdQual3A level and above   0.0034 ** \nHEdQual3GCSE or equiv      4.2e-14 ***\nHEdQual3No Qual            < 2e-16 ***\nRsexFemale                  0.0884 .  \nRAgeCat25-34                0.2110    \nRAgeCat35-44                0.2968    \nRAgeCat45-54               1.8e-05 ***\nRAgeCat55-59                0.0003 ***\nRAgeCat60-64               2.3e-10 ***\nRAgeCat65+                 < 2e-16 ***\n---\nSignif. codes:  \n0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 3293.1  on 2912  degrees of freedom\nResidual deviance: 2922.5  on 2902  degrees of freedom\n  (1075 observations deleted due to missingness)\nAIC: 2945\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n:::\n\n\n\n  \n**Model interpretation**\n\n`Summary()` provide a broad overview of the model output, not dissimilar to other statistical software. \n  We can also examine  the content of fit1 and fit2  more in detail and requests a specific element, for example:\n    \n\n\n\n::: {.cell hash='main_body_cache/pdf/9.8_7c05618cd7b2bb0062d118187974e63d'}\n\n```{.r .cell-code}\n  ls(fit1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"aic\"               \"boundary\"         \n [3] \"call\"              \"coefficients\"     \n [5] \"contrasts\"         \"control\"          \n [7] \"converged\"         \"data\"             \n [9] \"deviance\"          \"df.null\"          \n[11] \"df.residual\"       \"effects\"          \n[13] \"family\"            \"fitted.values\"    \n[15] \"formula\"           \"iter\"             \n[17] \"linear.predictors\" \"method\"           \n[19] \"model\"             \"na.action\"        \n[21] \"null.deviance\"     \"offset\"           \n[23] \"prior.weights\"     \"qr\"               \n[25] \"R\"                 \"rank\"             \n[27] \"residuals\"         \"terms\"            \n[29] \"weights\"           \"xlevels\"          \n[31] \"y\"                \n```\n:::\n\n```{.r .cell-code}\n  round(fit1$coefficients,2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              (Intercept) HEdQual3A level and above \n                     1.50                     -0.21 \n    HEdQual3GCSE or equiv           HEdQual3No Qual \n                    -0.64                     -0.84 \n```\n:::\n\n```{.r .cell-code}\n### The coef() function will give the same output:\n  round(coef(fit1),2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              (Intercept) HEdQual3A level and above \n                     1.50                     -0.21 \n    HEdQual3GCSE or equiv           HEdQual3No Qual \n                    -0.64                     -0.84 \n```\n:::\n:::\n\n\n\n  It is beyond the remit of this guide to describe the full output of `glm()`. Please refer to the package documentation for more detailed explanations.\n  \n  Raw logistic regression coefficients measure the effect of variables on the probability of the outcome such as log(betaX)=P(y). It is common practice to  convert these into odd ratios  by exponentiating them, such as that betaX=exp(P(y)). The following code does this in R: \n    \n\n\n\n::: {.cell hash='main_body_cache/pdf/9.9_95a65f9aed0e108a463a85a1032b80fb'}\n\n```{.r .cell-code}\n  cbind(\n    exp(coef(fit2)),exp(confint(fit2))\n  ) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                                  2.5 %  97.5 %\n(Intercept)               3.0420 2.0618  4.5277\nHEdQual3A level and above 0.6793 0.5238  0.8795\nHEdQual3GCSE or equiv     0.3715 0.2868  0.4796\nHEdQual3No Qual           0.1486 0.1089  0.2016\nRsexFemale                0.8546 0.7131  1.0236\nRAgeCat25-34              0.7819 0.5300  1.1470\nRAgeCat35-44              1.2296 0.8317  1.8095\nRAgeCat45-54              2.3557 1.5886  3.4828\nRAgeCat55-59              2.3178 1.4718  3.6622\nRAgeCat60-64              4.9667 3.0428  8.2090\nRAgeCat65+                8.7066 5.7183 13.2697\n```\n:::\n:::\n\n\n\n  Using the `coef()` and `confint()` functions, the code above respectively extracts the coefficients and associated 95% confidence intervals from fit2 then collate them using `cbind()`.\n  \n  ** Plotting the coefficients ** -->\n    We can visualise the odd ratios and their confidence intervals using the `plot.model()` function from the ‘sjPlot’ package.\n  The ’sjPlot’ package needs to be installed and loaded\n  \n```\n  install.packages('sjPlot')\n```\n  \n\n\n\n::: {.cell hash='main_body_cache/pdf/9.10_c363e0254232e1639371530bb524f302'}\n\n```{.r .cell-code}\n  library(sjPlot)\n  set_theme(base = theme_minimal()) ### Default sets of options \n  plot_model(fit2,\n             colors = c(\"#702082\", \"#008755\") ### Added for better accessibility \n  ) \n```\n\n::: {.cell-output-display}\n![](main_body_files/figure-pdf/9.10-1.pdf){fig-pos='H' fig-alt='Horizontal line plot for the odds ratios of the regression of voting behaviour by qualification, age categories and gender together with their confidence intervals'}\n:::\n:::\n\n\n\n  \n  \n  **Assessing model fit**\n    The  Akaike Information Criterion (AIC) is a measure of relative fit for  maximum likelihood fitted models. It is used to compare the improvement in how several models fit some data relative to each other, allowing for the different number of parameters or degrees of freedom. The smaller the AIC, the better the fit. In order for the comparison to be valid, we need to ensure that the models were run with the same number of observations each time. As it is likely that the second model was run on a smaller sample, due to missing values for the Age and Sex variables, we will need to re-run the first one without.\n  \n  \n\n\n\n::: {.cell hash='main_body_cache/pdf/9.11_86c8aafd842edeabd7ce3fe564024ec7'}\n\n```{.r .cell-code}\n  fit1 <- glm(Voted2 ~ HEdQual3, data=bsa%>%\n                filter(!is.na(Rsex) & !is.na(RAgeCat)), family=binomial(link=logit))\n  \n  c(fit1$aic,fit2$aic)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 3245 2945\n```\n:::\n:::\n\n\n\n  We can see that the model controlling for gender and sex is a better fit to the data than the one without controls as it has an AIC of 2944.5 against 3244.5 for fit1.\n  \n  With the information about the deviance from fit1 and fit2, we can also compute the overall significance of the model, that is whether the difference between the deviance (another  likelihood-based measure of fit) for the fitted model is significantly different from that of the empty or null model. This is usually carried by conducting a chi square test, accounting for the differences in the number of parameters (ie degrees of freedom) between the two models. As with other R code, this can achieved step by step or in one go:\n    \n\n\n\n::: {.cell hash='main_body_cache/pdf/9.12_fe23ed5aa12362da7214bea24b283d1f'}\n\n```{.r .cell-code}\n  dev.d<-fit2$null.deviance - fit2$deviance \n  df.d<-fit2$df.null - fit2$df.residual\n  p<-1 - pchisq(dev.d, df.d)\n  c(dev.d,df.d,p)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 370.5  10.0   0.0\n```\n:::\n:::\n\n\n\n  The Chi square test indicates that the  difference in deviance of 370.5 with 10 degrees of freedom is highly significant (P<.001) \n  \\newpage\n  \n# Further information\n## Additional commands of interest\n  The following non exhaustive list provides a few examples of commands and packages that tackle common types of analysis which might be relevant to users of large UK surveys:\n  \n  - Further regression analysis: the `glm()` command  can be used for fitting a large number of regression including Poisson and multinomial models. The\n  packages ‘lme4’ and  ‘nlme’  are used to fit respectively linear and non linear multilevel models, also known as mixed models.\n  - Complex survey data and analysis commands and functions can be found in the ‘survey’ package. It includes commands for taking into account stratified and clustered samples, weights compute design effects and confidence intervals, etc.. \n  - For users interested in latent variable modelling the `factanal()` command from the `stats` package conducts factor analysis. Other resources are available in the `poLCA` (Latent Class Analysis), `ltm` (Latent Trait modelling), `sem` (Structural equation modelling) packages. The  `Lavaan` package aslso provides a wide range of functions for structural equation modelling including with categorical outcomes.\n  - Users interested in longitudinal and time series analysis will be interested in the  `stats`and the ‘tseries’ packages. The packages `survival` and `eha` deal with event history and survival analysis, whereas ‘grofit’ and ‘plm’ are designed for panel data and growth analyses.\n  \n  \n## Additional online resources\n  There are hundreds of web sites dedicated to R that users can consult, in addition to CRAN and the main R help list, R-Help with its searchable archives. A few of the most common ones are listed here: \n  \n - As with other statistical packages, the [UCLA](https://stats.oarc.ucla.edu/r/) website provides a good starting point for beginners\n - The [University of North Texas](http://bayes.acs.unt.edu:8083/BayesContent/class/Jon/R_SC/) provides useful links to R resources \n - [The R Bloggers website](https://www.r-bloggers.com) contains many posts about R - in particular useful [introductory information](https://www.r-bloggers.com/r-tutorial-series-r-beginners-guide-and-r-bloggers-updates/)\n - [Stackexchange](https://stats.stackexchange.com/) is not specific to R but contains many forum-type questions and answers raised by R users \n - [This website](https://www.harding.edu/fmccown/r/) presents useful basic information about graphs in R.\n - [The Centre for Multilevel modeling at Bristol University](https://www.bristol.ac.uk/cmm/learning/course.html)  has several pages dedicated to R users interested in Multilevel modeling\n  \n  \n  \\newpage\n  \n# References\n  - R Core Team. (2017). R: A language and environment for statistical computing. Vienna, Austria: R Foundation for Statistical Computing. Retrieved from https://www.r-project.org/ RStudio Team. (2016). \n  - RStudio: Integrated Development for R. Boston, USA: RStudio, Inc. Retrieved from http://www.rstudio.com/ \n  - Tennekes, M. (2017) tmap: Thematic Maps. R package version 1.10. Retrieved from https://cran.r-project.org/package=tmap \n  - Wickham, H., & Francois, R. (2016). dplyr: A Grammar of Data Manipulation. R package version 0.5.0. Retrieved from https://cran.r-project.org/package=dplyr \n  - Wickham, H. ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York, 2009. Retrieved from https://cran.r-project.org/package=ggplot2\n  ",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}